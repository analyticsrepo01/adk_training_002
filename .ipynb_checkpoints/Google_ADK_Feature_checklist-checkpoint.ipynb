{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJgstGTJCuB-"
   },
   "source": [
    "# Google ADK: Feature List\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yRoDt3_c9Mq"
   },
   "source": [
    "# Pick a way to install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB5kKVRuBSdA"
   },
   "source": [
    "## Install Latest ADK from PyPi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0RD9-BaY4KY",
    "outputId": "e6d09458-02c9-4298-ce54-676e132693bb",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-adk in /opt/conda/lib/python3.10/site-packages (1.4.2)\n",
      "Collecting google-adk\n",
      "  Downloading google_adk-1.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.2 in /opt/conda/lib/python3.10/site-packages (from google-adk) (6.0.2)\n",
      "Requirement already satisfied: anyio>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (4.9.0)\n",
      "Requirement already satisfied: authlib>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.5.2)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from google-adk) (8.1.8)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (0.115.13)\n",
      "Requirement already satisfied: google-api-python-client>=2.157.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.169.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.95.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.95.1)\n",
      "Requirement already satisfied: google-cloud-secret-manager>=2.22.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.24.0)\n",
      "Requirement already satisfied: google-cloud-speech>=2.30.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.32.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.19.0)\n",
      "Requirement already satisfied: google-genai>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.21.1)\n",
      "Requirement already satisfied: graphviz>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from google-adk) (0.20.3)\n",
      "Requirement already satisfied: mcp>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.9.4)\n",
      "Requirement already satisfied: opentelemetry-api>=1.31.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-gcp-trace>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.9.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.31.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.34.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-adk) (2.11.7)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.32.4 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.32.4)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (2.0.37)\n",
      "Requirement already satisfied: starlette>=0.46.2 in /opt/conda/lib/python3.10/site-packages (from google-adk) (0.46.2)\n",
      "Requirement already satisfied: tenacity>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/conda/lib/python3.10/site-packages (from google-adk) (4.13.2)\n",
      "Requirement already satisfied: tzlocal>=5.3 in /opt/conda/lib/python3.10/site-packages (from google-adk) (5.3.1)\n",
      "Requirement already satisfied: uvicorn>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (0.34.0)\n",
      "Requirement already satisfied: watchdog>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from google-adk) (6.0.0)\n",
      "Requirement already satisfied: websockets>=15.0.1 in /opt/conda/lib/python3.10/site-packages (from google-adk) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio>=4.9.0->google-adk) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=4.9.0->google-adk) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=4.9.0->google-adk) (1.3.1)\n",
      "Requirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from authlib>=1.5.1->google-adk) (44.0.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=2.157.0->google-adk) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=2.157.0->google-adk) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=2.157.0->google-adk) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=2.157.0->google-adk) (2.24.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=2.157.0->google-adk) (4.1.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (5.29.4)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (24.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.34.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (2.0.7)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (0.16)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.0.0)\n",
      "Requirement already satisfied: google-cloud-trace<2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.16.1)\n",
      "Requirement already satisfied: google-cloud-logging<4 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (3.12.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-secret-manager>=2.22.0->google-adk) (0.14.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->google-adk) (1.6.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai>=1.21.1->google-adk) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/conda/lib/python3.10/site-packages (from mcp>=1.8.0->google-adk) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from mcp>=1.8.0->google-adk) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from mcp>=1.8.0->google-adk) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from mcp>=1.8.0->google-adk) (2.3.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.31.0->google-adk) (7.2.1)\n",
      "Requirement already satisfied: opentelemetry-resourcedetector-gcp==1.*,>=1.5.0dev0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-gcp-trace>=1.9.0->google-adk) (1.9.0a0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.31.0->google-adk) (0.55b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jupyter/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.9.0.post0->google-adk) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.4->google-adk) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.4->google-adk) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.4->google-adk) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=2.0->google-adk) (3.1.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.34.0->google-adk) (0.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=2.157.0->google-adk) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.6.1)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (0.3.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=2.157.0->google-adk) (3.2.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.21.1->google-adk) (1.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.31.0->google-adk) (3.21.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform>=1.95.1->google-cloud-aiplatform[agent-engines]>=1.95.1->google-adk) (1.26.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->authlib>=1.5.1->google-adk) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib>=1.5.1->google-adk) (2.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.157.0->google-adk) (0.6.1)\n",
      "Downloading google_adk-1.7.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m327.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-adk\n",
      "  Attempting uninstall: google-adk\n",
      "    Found existing installation: google-adk 1.4.2\n",
      "    Uninstalling google-adk-1.4.2:\n",
      "      Successfully uninstalled google-adk-1.4.2\n",
      "Successfully installed google-adk-1.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-adk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1I-NWQnsC2dD"
   },
   "source": [
    "## Install Nightly Wheel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "inJX7XNhdPhM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth, userdata\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZYjTNfr-Z41",
    "outputId": "b801dc76-6c30-41b5-f198-b0d2ab5aab6e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCaNsi2aC_fn"
   },
   "source": [
    "# Prerequeist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wa7T3roE9_x"
   },
   "source": [
    "## Imports & Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78LJOeGLdnua",
    "outputId": "ca189149-c94e-4246-b6c7-0bf0bbf98ae4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-adk\n",
      "Version: 1.7.0\n",
      "Summary: Agent Development Kit\n",
      "Home-page: https://google.github.io/adk-docs/\n",
      "Author: \n",
      "Author-email: Google LLC <googleapis-packages@google.com>\n",
      "License: \n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: anyio, authlib, click, fastapi, google-api-python-client, google-cloud-aiplatform, google-cloud-secret-manager, google-cloud-speech, google-cloud-storage, google-genai, graphviz, mcp, opentelemetry-api, opentelemetry-exporter-gcp-trace, opentelemetry-sdk, pydantic, python-dateutil, python-dotenv, PyYAML, requests, sqlalchemy, starlette, tenacity, typing-extensions, tzlocal, uvicorn, watchdog, websockets\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r0d7LoGKE7yp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.agents import BaseAgent, LlmAgent, Agent, SequentialAgent, LoopAgent, ParallelAgent\n",
    "from google.adk.agents.readonly_context import ReadonlyContext\n",
    "from google.adk.tools import ToolContext, LongRunningFunctionTool\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.sessions import Session\n",
    "from google.adk.events import Event\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5eifRzFGE_Q"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "\n",
    "APP_NAME = 'test_app'\n",
    "USER_ID = 'test_user'\n",
    "\n",
    "def create_runner(agent: BaseAgent):\n",
    "  return InMemoryRunner(agent, app_name=APP_NAME)\n",
    "\n",
    "def _content_to_text(content: types.Content | None) -> str:\n",
    "  if not content or not content.parts:\n",
    "    return ''\n",
    "  return ''.join([p.text or '' for p in content.parts])\n",
    "\n",
    "def print_event(event: Event):\n",
    "  print(f'Author: {event.author}')\n",
    "  print(f'Content Text: {_content_to_text(event.content)}')\n",
    "  print(f'Event: {event.model_dump(exclude_none=True, exclude_defaults=True)}')\n",
    "\n",
    "async def run_session(new_message: types.Content, *, runner: Runner, session: Optional[Session] = None, state: Optional[dict[str, Any]] = None) -> Session:\n",
    "  if session is None:\n",
    "    session = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, state=state)\n",
    "\n",
    "  print(f'User: {_content_to_text(new_message)}')\n",
    "  print('----------------------------------')\n",
    "  async for e in runner.run_async(user_id=USER_ID, session_id=session.id, new_message=new_message):\n",
    "    print_event(e)\n",
    "  print('----------------------------------')\n",
    "\n",
    "  session = await runner.session_service.get_session(app_name=session.app_name, user_id=session.user_id, session_id=session.id)\n",
    "  return session\n",
    "\n",
    "def content_text(msg: str) -> types.Content:\n",
    "  return types.UserContent(parts=[types.Part(text=msg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAyQqphdFTKj"
   },
   "source": [
    "## Set up envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsSKMdNtFAw1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "BACKEND = 'Vertex AI'  #@param ['Google AI', 'Vertex AI']\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyDE8OIxzLxqBg3oUj3g1AHTwXL6j775kI0'  #@param {type: \"string\"}\n",
    "\n",
    "import os\n",
    "\n",
    "# Cloud project id.\n",
    "PROJECT_IDS = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_IDS[0]  # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID:\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "GOOGLE_CLOUD_LOCATION = 'us-central1'  #@param {type: \"string\"}\n",
    "\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = '1' if BACKEND == 'Vertex AI' else '0'\n",
    "os.environ['GOOGLE_CLOUD_PROJECT'] = GOOGLE_CLOUD_PROJECT\n",
    "os.environ['GOOGLE_CLOUD_LOCATION'] = GOOGLE_CLOUD_LOCATION\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZsjYVKCEyZz"
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY0s7gMSV30i"
   },
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtlODxpaE4_J"
   },
   "source": [
    "### Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT8gvOUkExJA"
   },
   "outputs": [],
   "source": [
    "basic_agent = Agent(\n",
    "    name='basic_agent',\n",
    "    description='A helpful assistant for user.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"Answer user's question with your best knowledge.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T08s3jaqIXFZ",
    "outputId": "dde28f9a-4e7d-40c8-aae4-81c6f5624eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello!\n",
      "----------------------------------\n",
      "Author: basic_agent\n",
      "Content Text: Hello! How can I help you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello! How can I help you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 10, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 10}], 'prompt_token_count': 40, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 40}], 'total_token_count': 50, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-7015b151-5058-4348-b218-9312681f982d', 'author': 'basic_agent', 'id': '378d4073-6feb-4231-a0b0-d49c3e6a436c', 'timestamp': 1752106634.694778}\n",
      "----------------------------------\n",
      "User: Tell me a joke under 30 words?\n",
      "----------------------------------\n",
      "Author: basic_agent\n",
      "Content Text: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "Event: {'content': {'parts': [{'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 16, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 16}], 'prompt_token_count': 60, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 60}], 'total_token_count': 76, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-65ca8a3e-f4a5-43d8-815e-0bbfa6908a89', 'author': 'basic_agent', 'id': '72a3b720-7a1a-408e-aff2-f79149f78791', 'timestamp': 1752106636.049655}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(basic_agent)\n",
    "session = await run_session(content_text('Hello!'), runner=runner)\n",
    "session = await run_session(content_text('Tell me a joke under 30 words?'), runner=runner, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAala4e5ik75"
   },
   "source": [
    "### Non-LLM Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-ydBlV1jHn2"
   },
   "outputs": [],
   "source": [
    "sub_agent_1 = Agent(\n",
    "    name='sub_agent_1',\n",
    "    description='No.1 sub agent.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"JUST SAY 1.\",\n",
    ")\n",
    "\n",
    "sub_agent_2 = Agent(\n",
    "    name='sub_agent_2',\n",
    "    description='No.2 sub agent.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"JUST SAY 2.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR70VUb6iw6t"
   },
   "source": [
    "#### Sequential Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY1s8zeuisQe"
   },
   "outputs": [],
   "source": [
    "sequential_agent = SequentialAgent(\n",
    "    name='sequential_agent',\n",
    "    sub_agents=[sub_agent_1, sub_agent_2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9Qj5A2Uirmh",
    "outputId": "cece88a6-281f-47bf-f3e7-1e8c55bbcc0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello!\n",
      "----------------------------------\n",
      "Author: sub_agent_1\n",
      "Content Text: 1.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': '1.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 3, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 3}], 'prompt_token_count': 37, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 37}], 'total_token_count': 40, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-0fa15f7b-59d8-4d81-8a1a-8ccfca0bdc04', 'author': 'sub_agent_1', 'id': 'cc9edf1a-fba3-44ab-bf18-cf2c3956d2c3', 'timestamp': 1752106637.355679}\n",
      "Author: sub_agent_2\n",
      "Content Text: 2.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': '2.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 3, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 3}], 'prompt_token_count': 53, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 53}], 'total_token_count': 56, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-0fa15f7b-59d8-4d81-8a1a-8ccfca0bdc04', 'author': 'sub_agent_2', 'id': '0925cf8c-cfbc-4a03-84a2-42b4612a1436', 'timestamp': 1752106638.530287}\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nAuthor: child_1_agent\\nContent Text: 1.\\n\\n...\\n\\nAuthor: child_2_agent\\nContent Text: 2.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = create_runner(sequential_agent)\n",
    "session = await run_session(content_text('Hello!'), runner=runner)\n",
    "\n",
    "# Expect output:\n",
    "\"\"\"\n",
    "Author: child_1_agent\n",
    "Content Text: 1.\n",
    "\n",
    "...\n",
    "\n",
    "Author: child_2_agent\n",
    "Content Text: 2.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dIOwroUQ-17"
   },
   "source": [
    "#### ParallelAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCFE3a-rfAIA"
   },
   "outputs": [],
   "source": [
    "def roll_die(sides: int) -> int:\n",
    "  \"\"\"Roll a die and return the rolled result.\n",
    "\n",
    "  Args:\n",
    "    sides: The integer number of sides the die has.\n",
    "\n",
    "  Returns:\n",
    "    An integer of the result of rolling the die.\n",
    "  \"\"\"\n",
    "  return random.randint(1, sides)\n",
    "\n",
    "\n",
    "single_agent_1 = Agent(\n",
    "    name='async_agent_1',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 8 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "single_agent_2 = Agent(\n",
    "    name='async_agent_2',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 10 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "single_agent_3 = Agent(\n",
    "    name='async_agent_3',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 15 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "parallel_agent = ParallelAgent(\n",
    "    name='parallel_agent',\n",
    "    sub_agents=[\n",
    "        single_agent_1,\n",
    "        single_agent_2,\n",
    "        single_agent_3,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "to465Pmxx00j",
    "outputId": "80b0513c-0ddb-4751-e908-95c909d4faf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello!\n",
      "----------------------------------\n",
      "Author: async_agent_3\n",
      "Content Text: Hello! How can I help you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello! How can I help you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 10, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 10}], 'prompt_token_count': 88, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 88}], 'total_token_count': 98, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-e33f234a-440f-4ea3-9c10-77f74aae7f85', 'author': 'async_agent_3', 'branch': 'parallel_agent.async_agent_3', 'id': '4591121e-48c3-4d46-9cc0-8bf6251d1b6e', 'timestamp': 1752106640.559827}\n",
      "Author: async_agent_1\n",
      "Content Text: Hello! How can I assist you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello! How can I assist you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 10, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 10}], 'prompt_token_count': 87, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 87}], 'total_token_count': 97, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-e33f234a-440f-4ea3-9c10-77f74aae7f85', 'author': 'async_agent_1', 'branch': 'parallel_agent.async_agent_1', 'id': '6aa1a163-8c42-4fd2-84c8-1cfcb8b0dcdc', 'timestamp': 1752106639.756215}\n",
      "Author: async_agent_2\n",
      "Content Text: Hello! How can I help you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello! How can I help you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 10, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 10}], 'prompt_token_count': 88, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 88}], 'total_token_count': 98, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-e33f234a-440f-4ea3-9c10-77f74aae7f85', 'author': 'async_agent_2', 'branch': 'parallel_agent.async_agent_2', 'id': 'a12bbafe-d54b-4753-b82b-7f9c18060bb3', 'timestamp': 1752106640.194689}\n",
      "----------------------------------\n",
      "User: Roll a dice of 100 sides and tell me what you got.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: async_agent_1\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-0ee06fd3-499f-4efe-bdb1-59693d171fe8', 'args': {'sides': 100}, 'name': 'roll_die'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 5, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 5}], 'prompt_token_count': 101, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 101}], 'total_token_count': 106, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_1', 'long_running_tool_ids': set(), 'branch': 'parallel_agent.async_agent_1', 'id': '378761e5-198d-44cb-85ec-67aa34d82450', 'timestamp': 1752106642.339718}\n",
      "Author: async_agent_1\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-0ee06fd3-499f-4efe-bdb1-59693d171fe8', 'name': 'roll_die', 'response': {'result': 79}}}], 'role': 'user'}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_1', 'branch': 'parallel_agent.async_agent_1', 'id': '002a74ca-89ae-46e5-9f97-48f985575523', 'timestamp': 1752106645.516666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: async_agent_2\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-8378033a-550a-4bbd-8786-41ee6d7bd562', 'args': {'sides': 10}, 'name': 'roll_die'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 5, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 5}], 'prompt_token_count': 102, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 102}], 'total_token_count': 107, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_2', 'long_running_tool_ids': set(), 'branch': 'parallel_agent.async_agent_2', 'id': '936bb1da-9185-4365-953f-30edb9ef5655', 'timestamp': 1752106643.479023}\n",
      "Author: async_agent_3\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-066691ae-c029-4986-90f4-d451b1ee9633', 'args': {'sides': 100}, 'name': 'roll_die'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 5, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 5}], 'prompt_token_count': 102, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 102}], 'total_token_count': 107, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_3', 'long_running_tool_ids': set(), 'branch': 'parallel_agent.async_agent_3', 'id': '12621b37-f847-4450-905e-8acaf74dd97b', 'timestamp': 1752106644.138941}\n",
      "Author: async_agent_2\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-8378033a-550a-4bbd-8786-41ee6d7bd562', 'name': 'roll_die', 'response': {'result': 3}}}], 'role': 'user'}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_2', 'branch': 'parallel_agent.async_agent_2', 'id': '33834246-0d97-4eb4-bca0-23b41c165c91', 'timestamp': 1752106646.105008}\n",
      "Author: async_agent_3\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-066691ae-c029-4986-90f4-d451b1ee9633', 'name': 'roll_die', 'response': {'result': 13}}}], 'role': 'user'}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_3', 'branch': 'parallel_agent.async_agent_3', 'id': '52bad4f1-c603-4a7a-8bbb-d7cf19cf703a', 'timestamp': 1752106646.105376}\n",
      "Author: async_agent_1\n",
      "Content Text: I rolled a 100-sided die and got 79.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I rolled a 100-sided die and got 79.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 17, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 17}], 'prompt_token_count': 111, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 111}], 'total_token_count': 128, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_1', 'branch': 'parallel_agent.async_agent_1', 'id': 'fb0970bd-b479-4820-8fdd-7c57d42a6b23', 'timestamp': 1752106645.532158}\n",
      "Author: async_agent_2\n",
      "Content Text: I rolled a 10-sided die and got a 3.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I rolled a 10-sided die and got a 3.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 16, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 16}], 'prompt_token_count': 112, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 112}], 'total_token_count': 128, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_2', 'branch': 'parallel_agent.async_agent_2', 'id': '93d8a22c-8445-4a1f-a049-db4b5bc03275', 'timestamp': 1752106646.1182}\n",
      "Author: async_agent_3\n",
      "Content Text: I rolled a 100-sided die and got 13.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I rolled a 100-sided die and got 13.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 17, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 17}], 'prompt_token_count': 112, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 112}], 'total_token_count': 129, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-efe2009f-ca55-402f-8a21-4dbee9b8def8', 'author': 'async_agent_3', 'branch': 'parallel_agent.async_agent_3', 'id': 'a4d4e700-0ee8-429c-9704-03d2aedd3958', 'timestamp': 1752106646.538999}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(parallel_agent)\n",
    "session = await run_session(content_text('Hello!'), runner=runner)\n",
    "session = await run_session(content_text('Roll a dice of 100 sides and tell me what you got.'), runner=runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KszPFnxhjvd"
   },
   "source": [
    "### LlmAgent.output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThUOR1A-hrCR",
    "outputId": "d0a20a6c-f9e5-48d7-a2b3-b3c47083861b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Gets weahter data of San Jose, CA.\n",
      "----------------------------------\n",
      "Author: weather_agent\n",
      "Content Text: {\n",
      "\"temperature\": 29,\n",
      "\"wind_direction\": \"North East\"\n",
      "}\n",
      "Event: {'content': {'parts': [{'text': '{\\n\"temperature\": 29,\\n\"wind_direction\": \"North East\"\\n}'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 21, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 21}], 'prompt_token_count': 120, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 120}], 'total_token_count': 141, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-afd24a47-d215-4e43-86ad-16b7e5407d9e', 'author': 'weather_agent', 'id': 'bf226f49-ab2c-4fa2-8f18-490d596930a0', 'timestamp': 1752106648.136469}\n",
      "----------------------------------\n",
      "Expected output:\n",
      "Content Text: {\n",
      "\"temperature\": 29,\n",
      "\"wind_direction\": \"North East\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WeatherData(BaseModel):\n",
    "  temperature: int\n",
    "  wind_direction: str\n",
    "\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "  weather_data: WeatherData\n",
    "\n",
    "weather_agent = LlmAgent(\n",
    "    name='weather_agent',\n",
    "    description='A helpful assistant for weather data.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    output_schema=WeatherData,\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    "    instruction=\"\"\"Answer user's question with your best knowledge.\n",
    "Here are some context:\n",
    "\n",
    "Weather in San Jose, CA:\n",
    "- Temperature: 29C\n",
    "- Wind direction: North East\n",
    "\n",
    "Weather in Cupertino, CA:\n",
    "- Temperature: -5C\n",
    "- Wind direction: South West\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "runner = create_runner(weather_agent)\n",
    "session = await run_session(content_text('Gets weahter data of San Jose, CA.'), runner=runner)\n",
    "\n",
    "print(\"\"\"Expected output:\n",
    "Content Text: {\n",
    "\"temperature\": 29,\n",
    "\"wind_direction\": \"North East\"\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3lYcCS7pld2"
   },
   "source": [
    "#### As AgentTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ST8J0nutqJaW",
    "outputId": "75dd0e33-a48b-4455-f8ba-c9c334be5ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Gets weahter data of San Jose, CA.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-85a79677-bab2-4338-ac2c-fa24d738a5e5', 'args': {'request': 'San Jose, CA'}, 'name': 'weather_agent'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 8, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 8}], 'prompt_token_count': 63, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 63}], 'total_token_count': 71, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-984ecb5a-257d-4103-961f-d0429b3fe66b', 'author': 'root_agent', 'long_running_tool_ids': set(), 'id': '96409ec8-9d9a-4757-9110-ab3bad3ae60b', 'timestamp': 1752106649.172044}\n",
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-85a79677-bab2-4338-ac2c-fa24d738a5e5', 'name': 'weather_agent', 'response': {'temperature': 29, 'wind_direction': 'North East'}}}], 'role': 'user'}, 'invocation_id': 'e-984ecb5a-257d-4103-961f-d0429b3fe66b', 'author': 'root_agent', 'id': '7eec295b-5581-4b40-9dd6-63ce235e1ed6', 'timestamp': 1752106651.654526}\n",
      "Author: root_agent\n",
      "Content Text: OK. The temperature in San Jose, CA is 29 degrees, and the wind direction is North East.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'OK. The temperature in San Jose, CA is 29 degrees, and the wind direction is North East.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 24, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 24}], 'prompt_token_count': 81, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 81}], 'total_token_count': 105, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-984ecb5a-257d-4103-961f-d0429b3fe66b', 'author': 'root_agent', 'id': 'e5ee67df-fd5f-4d18-a031-9d1ab64cd136', 'timestamp': 1752106651.658598}\n",
      "----------------------------------\n",
      "Expected output (similar to below):\n",
      "Content Text: OK. The weather data for San Jose, CA is: Temperature is 29, and wind direction is North East.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_agent = LlmAgent(\n",
    "    name='root_agent',\n",
    "    description='A helpful assistant for user.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"\"\"Answer user's question with your best knowledge.\"\"\",\n",
    "    tools=[AgentTool(agent=weather_agent)],\n",
    ")\n",
    "\n",
    "runner = create_runner(root_agent)\n",
    "session = await run_session(content_text('Gets weahter data of San Jose, CA.'), runner=runner)\n",
    "\n",
    "print(\"\"\"Expected output (similar to below):\n",
    "Content Text: OK. The weather data for San Jose, CA is: Temperature is 29, and wind direction is North East.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYlJkVC-ACWi"
   },
   "source": [
    "## Agent - Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHjjMeijAFMn"
   },
   "outputs": [],
   "source": [
    "async def assert_session_values(\n",
    "    ctx: CallbackContext,\n",
    "    *,\n",
    "    keys_in_ctx_session: Optional[list[str]] = None,\n",
    "    keys_in_service_session: Optional[list[str]] = None,\n",
    "    keys_not_in_service_session: Optional[list[str]] = None,\n",
    "):\n",
    "  session_in_ctx = ctx._invocation_context.session\n",
    "  session_in_service = await ctx._invocation_context.session_service.get_session(\n",
    "      app_name=session_in_ctx.app_name, user_id=session_in_ctx.user_id, session_id=session_in_ctx.id\n",
    "  )\n",
    "  assert session_in_service is not None\n",
    "\n",
    "  for key in keys_in_ctx_session or []:\n",
    "    assert key in session_in_ctx.state\n",
    "\n",
    "  for key in keys_in_service_session or []:\n",
    "    assert key in session_in_service.state\n",
    "\n",
    "  for key in keys_not_in_service_session or []:\n",
    "    assert key not in session_in_service.state\n",
    "\n",
    "\n",
    "async def before_agent(callback_context: CallbackContext) -> Optional[types.Content]:\n",
    "  if 'before_agent_callback_var' in callback_context.state:\n",
    "    return types.ModelContent('Sorry, I can only reply onces.')\n",
    "\n",
    "  callback_context.state['before_agent_callback_var'] = (\n",
    "      'before_agent_callback_var_value'\n",
    "  )\n",
    "\n",
    "  await assert_session_values(\n",
    "      callback_context,\n",
    "      keys_not_in_service_session=['before_agent_callback_var'],\n",
    "  )\n",
    "\n",
    "\n",
    "async def after_agent(callback_context: CallbackContext):\n",
    "  callback_context.state['after_agent_callback_var'] = (\n",
    "      'after_agent_callback_var_value'\n",
    "  )\n",
    "\n",
    "  await assert_session_values(\n",
    "      callback_context,\n",
    "      keys_in_ctx_session=['before_agent_callback_var'],\n",
    "      keys_in_service_session=['before_agent_callback_var'],\n",
    "      keys_not_in_service_session=['after_agent_callback_var'],\n",
    "  )\n",
    "\n",
    "\n",
    "async def log_query(query: str, tool_context: ToolContext):\n",
    "  print(f'User query: {query}')\n",
    "\n",
    "  tool_context.state['log_query_var'] = 'log_query_var_value'\n",
    "  await assert_session_values(\n",
    "      tool_context,\n",
    "      keys_in_ctx_session=[\n",
    "          'before_agent_callback_var',\n",
    "          'log_query_var',\n",
    "      ],\n",
    "      keys_in_service_session=['before_agent_callback_var'],\n",
    "      keys_not_in_service_session=[\n",
    "          'after_agent_callback_var',\n",
    "          'log_query_var',\n",
    "      ],\n",
    "  )\n",
    "\n",
    "\n",
    "root_agent = Agent(\n",
    "    name='root_agent',\n",
    "    description='a verification agent.',\n",
    "    instruction=(\n",
    "        'Log all users query with `log_query` tool. Must always remind user you'\n",
    "        ' cannot answer second query because your setup.'\n",
    "    ),\n",
    "    model='gemini-2.0-flash-001',\n",
    "    tools=[log_query],\n",
    "    before_agent_callback=before_agent,\n",
    "    after_agent_callback=after_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L40uv2YeAQb6",
    "outputId": "28f6e7ea-b9e9-44a0-faf3-9ee76fad5082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, there!\n",
      "----------------------------------\n",
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'invocation_id': 'e-930b0022-1ac0-4f95-a701-e875155ab973', 'author': 'root_agent', 'actions': {'state_delta': {'before_agent_callback_var': 'before_agent_callback_var_value'}}, 'id': '0413f703-e0cf-4e19-b16c-b093a17f1802', 'timestamp': 1752106652.936431}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-9115f141-9bc6-4558-a492-b18636cdce8d', 'args': {'query': 'Hello, there!'}, 'name': 'log_query'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 8, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 8}], 'prompt_token_count': 62, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 62}], 'total_token_count': 70, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-930b0022-1ac0-4f95-a701-e875155ab973', 'author': 'root_agent', 'long_running_tool_ids': set(), 'id': 'ced14ce1-666e-4fff-b29b-d94d7990a48f', 'timestamp': 1752106652.93719}\n",
      "User query: Hello, there!\n",
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-9115f141-9bc6-4558-a492-b18636cdce8d', 'name': 'log_query', 'response': {'result': None}}}], 'role': 'user'}, 'invocation_id': 'e-930b0022-1ac0-4f95-a701-e875155ab973', 'author': 'root_agent', 'actions': {'state_delta': {'log_query_var': 'log_query_var_value'}}, 'id': '491c8eb6-96c9-47b9-817d-58b1638f6a1c', 'timestamp': 1752106653.875773}\n",
      "Author: root_agent\n",
      "Content Text: Hello! How can I help you today? Please remember that I can only address one query at a time due to my current setup.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello! How can I help you today? Please remember that I can only address one query at a time due to my current setup.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 28, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 28}], 'prompt_token_count': 75, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 75}], 'total_token_count': 103, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-930b0022-1ac0-4f95-a701-e875155ab973', 'author': 'root_agent', 'id': 'a2983ff0-f5b6-41e4-b092-b4ec193d3b75', 'timestamp': 1752106653.878235}\n",
      "Author: root_agent\n",
      "Content Text: \n",
      "Event: {'invocation_id': 'e-930b0022-1ac0-4f95-a701-e875155ab973', 'author': 'root_agent', 'actions': {'state_delta': {'after_agent_callback_var': 'after_agent_callback_var_value'}}, 'id': '80399728-988c-4c1a-9d84-2fde9885d47b', 'timestamp': 1752106655.036117}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(root_agent)\n",
    "session = await run_session(content_text('Hello, there!'), runner=runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnRk_QNMuAvP"
   },
   "source": [
    "## Agent Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "px_n_hLIuH5l"
   },
   "source": [
    "### Delegate\n",
    "\n",
    "* Delegate to sub-agent and sub-agent can continue to reploy to user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z91ljNxiuLxp"
   },
   "outputs": [],
   "source": [
    "sub_agent_1 = Agent(\n",
    "    name='manager_agent',\n",
    "    description='Can respond to user when they ask for manager.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"\"\"Answer user's question with your best knowledge.\"\"\",\n",
    ")\n",
    "\n",
    "sub_agent_2 = Agent(\n",
    "    name='supervisor_agent',\n",
    "    description='Can respond to user when they ask for supervisor.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"\"\"Answer user's question with your best knowledge.\"\"\",\n",
    ")\n",
    "\n",
    "root_agent = Agent(\n",
    "    name='customer_support_agent',\n",
    "    description=\"Can respond to users' general question.\",\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"\"\"Answer user's question with your best knowledge.\"\"\",\n",
    "    sub_agents=[sub_agent_1, sub_agent_2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lARnebDu3MH",
    "outputId": "dbafe58c-de18-4f26-816d-708bdb4b6fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "----------------------------------\n",
      "Author: customer_support_agent\n",
      "Content Text: Hi there! How can I help you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hi there! How can I help you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 11, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 11}], 'prompt_token_count': 240, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 240}], 'total_token_count': 251, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-d6f5204d-6f70-46c8-acaf-607a0073867b', 'author': 'customer_support_agent', 'id': '74d8e7b0-b11e-4edf-86cf-b9cc16febad4', 'timestamp': 1752106655.064505}\n",
      "----------------------------------\n",
      "User: I need talk to your manager.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: customer_support_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-11363281-9eeb-4e1f-a96f-0612a255da04', 'args': {'agent_name': 'manager_agent'}, 'name': 'transfer_to_agent'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 11, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 11}], 'prompt_token_count': 258, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 258}], 'total_token_count': 269, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-bec4a4a4-f6e1-4d03-a08d-71f4ff5cf93c', 'author': 'customer_support_agent', 'long_running_tool_ids': set(), 'id': '72e38e24-5522-4dde-a024-12611924297e', 'timestamp': 1752106656.066135}\n",
      "Author: customer_support_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-11363281-9eeb-4e1f-a96f-0612a255da04', 'name': 'transfer_to_agent', 'response': {'result': None}}}], 'role': 'user'}, 'invocation_id': 'e-bec4a4a4-f6e1-4d03-a08d-71f4ff5cf93c', 'author': 'customer_support_agent', 'actions': {'transfer_to_agent': 'manager_agent'}, 'id': '35e21595-2b6d-4098-ae61-bee52885bf5b', 'timestamp': 1752106657.196629}\n",
      "Author: manager_agent\n",
      "Content Text: Hello, I am the manager. How can I assist you today?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'Hello, I am the manager. How can I assist you today?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 15, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 15}], 'prompt_token_count': 365, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 365}], 'total_token_count': 380, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-bec4a4a4-f6e1-4d03-a08d-71f4ff5cf93c', 'author': 'manager_agent', 'id': '617af04a-7f26-4f5e-b9b0-a12ae1cc679b', 'timestamp': 1752106657.199347}\n",
      "----------------------------------\n",
      "User: Who are you?\n",
      "----------------------------------\n",
      "Author: manager_agent\n",
      "Content Text: I'm the manager.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': \"I'm the manager.\\n\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 7, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 7}], 'prompt_token_count': 384, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 384}], 'total_token_count': 391, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-d0b89447-4178-4085-9a96-464c987d414e', 'author': 'manager_agent', 'id': 'b13a88eb-702b-402d-afaf-32182a1591b9', 'timestamp': 1752106658.330095}\n",
      "----------------------------------\n",
      "User: OK, now I need supervisor\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: manager_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-a82f15a2-68a3-44b0-ac63-e59d48245563', 'args': {'agent_name': 'supervisor_agent'}, 'name': 'transfer_to_agent'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 11, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 11}], 'prompt_token_count': 397, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 397}], 'total_token_count': 408, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-b0b9c584-f045-4a20-9660-213473239e49', 'author': 'manager_agent', 'long_running_tool_ids': set(), 'id': '740c8d9f-c059-446e-84cf-d30a3d219cb8', 'timestamp': 1752106659.277138}\n",
      "Author: manager_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-a82f15a2-68a3-44b0-ac63-e59d48245563', 'name': 'transfer_to_agent', 'response': {'result': None}}}], 'role': 'user'}, 'invocation_id': 'e-b0b9c584-f045-4a20-9660-213473239e49', 'author': 'manager_agent', 'actions': {'transfer_to_agent': 'supervisor_agent'}, 'id': '9a2825b7-0ae3-4b0c-b134-a33ae9c8ea20', 'timestamp': 1752106660.488081}\n",
      "Author: supervisor_agent\n",
      "Content Text: I am the supervisor. How can I help you?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I am the supervisor. How can I help you?\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 12, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 12}], 'prompt_token_count': 471, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 471}], 'total_token_count': 483, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-b0b9c584-f045-4a20-9660-213473239e49', 'author': 'supervisor_agent', 'id': '08cc3cce-c915-4e89-8e15-ca380dee8118', 'timestamp': 1752106660.490061}\n",
      "----------------------------------\n",
      "User: Who are you?\n",
      "----------------------------------\n",
      "Author: supervisor_agent\n",
      "Content Text: I am the supervisor.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I am the supervisor.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 6, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 6}], 'prompt_token_count': 487, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 487}], 'total_token_count': 493, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-18613e44-97c5-41a7-b272-d3223a0d66a8', 'author': 'supervisor_agent', 'id': 'f5a5ae5b-df1d-4c25-ab42-4cb95016c362', 'timestamp': 1752106661.521698}\n",
      "----------------------------------\n",
      "User: Alright, you are all good. I still have some general questions.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: supervisor_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-57e85fb4-66f0-48c0-a474-dd18af3053ea', 'args': {'agent_name': 'customer_support_agent'}, 'name': 'transfer_to_agent'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 13, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 13}], 'prompt_token_count': 507, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 507}], 'total_token_count': 520, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-3a140cd0-4505-4842-8b65-46a32cfb0217', 'author': 'supervisor_agent', 'long_running_tool_ids': set(), 'id': 'a4897cbc-a176-4ad8-88e2-b8907c0c038c', 'timestamp': 1752106662.427867}\n",
      "Author: supervisor_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-57e85fb4-66f0-48c0-a474-dd18af3053ea', 'name': 'transfer_to_agent', 'response': {'result': None}}}], 'role': 'user'}, 'invocation_id': 'e-3a140cd0-4505-4842-8b65-46a32cfb0217', 'author': 'supervisor_agent', 'actions': {'transfer_to_agent': 'customer_support_agent'}, 'id': '06a4c34e-abeb-438f-90b2-55dff8ae6ec7', 'timestamp': 1752106663.466729}\n",
      "Author: customer_support_agent\n",
      "Content Text: Great! I'm here to help with your general questions. What's on your mind?\n",
      "\n",
      "Event: {'content': {'parts': [{'text': \"Great! I'm here to help with your general questions. What's on your mind?\\n\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 21, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 21}], 'prompt_token_count': 494, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 494}], 'total_token_count': 515, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-3a140cd0-4505-4842-8b65-46a32cfb0217', 'author': 'customer_support_agent', 'id': 'd0b75de2-bb5b-4690-90b9-bd0cd33aca83', 'timestamp': 1752106663.469424}\n",
      "----------------------------------\n",
      "User: Who are you?\n",
      "----------------------------------\n",
      "Author: customer_support_agent\n",
      "Content Text: I am a customer support agent. I can respond to your general questions.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I am a customer support agent. I can respond to your general questions.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 16, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 16}], 'prompt_token_count': 519, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 519}], 'total_token_count': 535, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-4e0b535f-fc95-4958-bf40-cbbbeaba0377', 'author': 'customer_support_agent', 'id': '560f60f6-1510-4264-9b20-c45844c3de2d', 'timestamp': 1752106664.450322}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(root_agent)\n",
    "session = await run_session(content_text('Hi'), runner=runner)\n",
    "session = await run_session(content_text('I need talk to your manager.'), runner=runner, session=session)\n",
    "session = await run_session(content_text('Who are you?'), runner=runner, session=session)\n",
    "session = await run_session(content_text('OK, now I need supervisor'), runner=runner, session=session)\n",
    "session = await run_session(content_text('Who are you?'), runner=runner, session=session)\n",
    "session = await run_session(content_text('Alright, you are all good. I still have some general questions.'), runner=runner, session=session)\n",
    "session = await run_session(content_text('Who are you?'), runner=runner, session=session)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZvsUvEKV-we"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVhQeleHGo0c"
   },
   "source": [
    "### LRO Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khANbFTvGq7Y"
   },
   "outputs": [],
   "source": [
    "def process_large_file(file_path: str, tool_context: ToolContext):\n",
    "    \"\"\"Processes the large file\"\"\"\n",
    "    tool_context.state['ongoing_file_job_function_call_id'] = tool_context.function_call_id\n",
    "    tool_context.state['ongoing_file_job_id'] = \"job_123\"\n",
    "    return {\n",
    "        'status': 'pending',\n",
    "        'resource_id': 'job_123'\n",
    "    }\n",
    "\n",
    "root_agent = Agent(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    name=\"file_processor_agent\",\n",
    "    tools=[LongRunningFunctionTool(func=process_large_file)],\n",
    "    description=\"You're an asistant for file processing.\",\n",
    "    instruction=\"\"\"Use the tool to help user process file.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEQmYtEcITqU",
    "outputId": "05147668-207f-41d5-aa67-98f66d3486ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Process this file: /path/to/my/large_file.txt\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: file_processor_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-284b2ccc-7a4d-49c9-982e-f14a95adea9c', 'args': {'file_path': '/path/to/my/large_file.txt'}, 'name': 'process_large_file'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 20, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 20}], 'prompt_token_count': 76, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 76}], 'total_token_count': 96, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-dd284fd4-db07-4b68-b58a-bcdb9494af6c', 'author': 'file_processor_agent', 'long_running_tool_ids': {'adk-284b2ccc-7a4d-49c9-982e-f14a95adea9c'}, 'id': '21bcb247-3939-4e4f-9d7c-ae6961bb6ab3', 'timestamp': 1752106666.001453}\n",
      "Author: file_processor_agent\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-284b2ccc-7a4d-49c9-982e-f14a95adea9c', 'name': 'process_large_file', 'response': {'status': 'pending', 'resource_id': 'job_123'}}}], 'role': 'user'}, 'invocation_id': 'e-dd284fd4-db07-4b68-b58a-bcdb9494af6c', 'author': 'file_processor_agent', 'actions': {'state_delta': {'ongoing_file_job_function_call_id': 'adk-284b2ccc-7a4d-49c9-982e-f14a95adea9c', 'ongoing_file_job_id': 'job_123'}}, 'id': 'e435e754-be68-40c5-8437-f131c4f96a10', 'timestamp': 1752106666.929946}\n",
      "Author: file_processor_agent\n",
      "Content Text: OK. I've submitted a job to process the file /path/to/my/large_file.txt. The job ID is job_123 and the current status is pending.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': \"OK. I've submitted a job to process the file /path/to/my/large_file.txt. The job ID is job_123 and the current status is pending.\\n\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 42, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 42}], 'prompt_token_count': 111, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 111}], 'total_token_count': 153, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-dd284fd4-db07-4b68-b58a-bcdb9494af6c', 'author': 'file_processor_agent', 'id': '18a8096e-8d81-41ec-ae82-00ebe9125f29', 'timestamp': 1752106666.932747}\n",
      "----------------------------------\n",
      "User: How are you?\n",
      "----------------------------------\n",
      "Author: file_processor_agent\n",
      "Content Text: I am doing well, thank you for asking. I am ready to help you process files.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I am doing well, thank you for asking. I am ready to help you process files.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 20, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 20}], 'prompt_token_count': 157, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 157}], 'total_token_count': 177, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-e3b7328d-5a8e-487b-a6e2-b45db1cd875a', 'author': 'file_processor_agent', 'id': '2d2c3503-9a7c-4392-a25f-f56a950a7b83', 'timestamp': 1752106668.077705}\n",
      "----------------------------------\n",
      "User: \n",
      "----------------------------------\n",
      "Author: file_processor_agent\n",
      "Content Text: I have processed the file /path/to/my/large_file.txt. The processing result is ok and the total bytes processed are 12MB.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': 'I have processed the file /path/to/my/large_file.txt. The processing result is ok and the total bytes processed are 12MB.\\n'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 35, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 35}], 'prompt_token_count': 111, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 111}], 'total_token_count': 146, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-2ccadc0a-5ad2-4ce0-ad43-ead670987b00', 'author': 'file_processor_agent', 'id': 'b38c91ef-339f-4e97-a340-50d6295fe82b', 'timestamp': 1752106669.22495}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(root_agent)\n",
    "session = await run_session(content_text('Process this file: /path/to/my/large_file.txt'), runner=runner)\n",
    "session = await run_session(content_text('How are you?'), runner=runner, session=session)\n",
    "\n",
    "# Later, when the LRO finishes, user need to create new FR to call the runner with it.\n",
    "fr = types.FunctionResponse(\n",
    "    # user is responsible for filling in function_call id, it can also be stored elsewhere instead of in session.\n",
    "    id=session.state['ongoing_file_job_function_call_id'],\n",
    "    name=\"process_large_file\",\n",
    "    response={\"result\": \"ok\", \"total_bytes_processed\": '12MB'},\n",
    ")\n",
    "session = await run_session(types.UserContent(parts=[types.Part(function_response=fr)]), runner=runner, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vylj_gLQ9-IG"
   },
   "source": [
    "### Google Search (Builtin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpqjjRhe-B6k"
   },
   "outputs": [],
   "source": [
    "from google.adk.tools import google_search\n",
    "\n",
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "\n",
    "google_search_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"external_google_search\",\n",
    "    tools=[google_search],\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    "    description=\"Uses `google_search` tool to get real-time information\",\n",
    "    instruction=\"\"\"You are an Google Search Agent, who uses the `google_search` tool for performing searches to answer user's question.\"\"\"\n",
    ")\n",
    "\n",
    "root_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"orchestrator\",\n",
    "    sub_agents=[google_search_agent],\n",
    "    description=\"You are a helpful assistant that can answer user's question\",\n",
    "    instruction=\"\"\"Please answer users' questions as best as possible.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3asAjF3-DRI",
    "outputId": "27ebdf26-3103-4adc-adda-50f09e8cd440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Search the informatino about Florida.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: orchestrator\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_call': {'id': 'adk-e3b9cb7c-2282-4c29-a84a-c8019dc3cd6d', 'args': {'agent_name': 'external_google_search'}, 'name': 'transfer_to_agent'}}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 13, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 13}], 'prompt_token_count': 232, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 232}], 'total_token_count': 245, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-3d58f70b-590e-4fe2-aba6-4dab578329fe', 'author': 'orchestrator', 'long_running_tool_ids': set(), 'id': 'b394cfc0-704b-4fb6-ad32-ba7c1b9647fc', 'timestamp': 1752106670.520644}\n",
      "Author: orchestrator\n",
      "Content Text: \n",
      "Event: {'content': {'parts': [{'function_response': {'id': 'adk-e3b9cb7c-2282-4c29-a84a-c8019dc3cd6d', 'name': 'transfer_to_agent', 'response': {'result': None}}}], 'role': 'user'}, 'invocation_id': 'e-3d58f70b-590e-4fe2-aba6-4dab578329fe', 'author': 'orchestrator', 'actions': {'transfer_to_agent': 'external_google_search'}, 'id': '2e4a41a7-3d2a-4eeb-9901-0580f086bdd8', 'timestamp': 1752106671.608482}\n",
      "Author: external_google_search\n",
      "Content Text: Florida is a state located in the Southeastern region of the United States. Here's some information about Florida: \n",
      "\n",
      " **Geography:** \n",
      "\n",
      " *   It is a peninsula, surrounded by water on three sides: the Gulf of Mexico to the west, the Atlantic Ocean to the east, and the Straits of Florida to the south. \n",
      " *   It shares a land border with Georgia and Alabama to the north. \n",
      " *   It has the longest coastline in the contiguous United States, with approximately 1,350 miles. \n",
      " *   Much of Florida has a relatively low elevation. The highest natural point is Britton Hill, which is only 345 feet above sea level. \n",
      " *   It is the only state that borders both the Atlantic Ocean and the Gulf of Mexico. \n",
      " *   The state spans two time zones. \n",
      " *   It is the southernmost of the 48 contiguous states. \n",
      " *   It is west of the Bahamas and about 90 miles north of Cuba. \n",
      " *   Florida has more than 7,700 lakes and 11,000 miles of rivers. \n",
      "\n",
      " **Climate:** \n",
      "\n",
      " *   Florida's climate ranges from subtropical in the north to tropical in the south. \n",
      "\n",
      " **Population:** \n",
      "\n",
      " *   With a population of over 23 million, it is the third-most populous state in the United States. \n",
      " *   Miami-Dade is the most populous county. \n",
      "\n",
      " **History:** \n",
      "\n",
      " *   Various Native American tribes inhabited Florida for at least 14,000 years. \n",
      " *   Juan Ponce de León, a Spanish explorer, discovered Florida in 1513. \n",
      " *   St. Augustine, founded by the Spanish in 1565, is the oldest continuously settled city in the United States. \n",
      " *   Florida was admitted as the 27th state to the United States on March 3, 1845. \n",
      "\n",
      " **Tourism and Recreation:** \n",
      "\n",
      " *   Florida is known for its beaches, amusement parks, warm climate and opportunities for nautical recreation. \n",
      " *   The state has a large number of state parks, forests, national parks and preserves. \n",
      " *   Tourism is a major industry in Florida. In 2024, Florida had a record of 143.0 million visitors. \n",
      " *   Top origin countries for visitors to Florida in 2024 include Canada, Brazil, the United Kingdom, Colombia, and Mexico. \n",
      "\n",
      " **Unique Ecosystems and Wildlife:** \n",
      "\n",
      " *   Florida has unique ecosystems, including the Everglades National Park. \n",
      " *  Everglades National Park is the only place where alligators and crocodiles coexist.\n",
      " *   The state is home to diverse wildlife, including the American alligator, American crocodile, American flamingo, Florida panther, bottlenose dolphin, and manatee. \n",
      " *   The Florida Reef is the only living coral barrier reef in the continental United States.\n",
      "\n",
      "Event: {'content': {'parts': [{'text': \"Florida is a state located in the Southeastern region of the United States. Here's some information about Florida: \\n\\n **Geography:** \\n\\n *   It is a peninsula, surrounded by water on three sides: the Gulf of Mexico to the west, the Atlantic Ocean to the east, and the Straits of Florida to the south. \\n *   It shares a land border with Georgia and Alabama to the north. \\n *   It has the longest coastline in the contiguous United States, with approximately 1,350 miles. \\n *   Much of Florida has a relatively low elevation. The highest natural point is Britton Hill, which is only 345 feet above sea level. \\n *   It is the only state that borders both the Atlantic Ocean and the Gulf of Mexico. \\n *   The state spans two time zones. \\n *   It is the southernmost of the 48 contiguous states. \\n *   It is west of the Bahamas and about 90 miles north of Cuba. \\n *   Florida has more than 7,700 lakes and 11,000 miles of rivers. \\n\\n **Climate:** \\n\\n *   Florida's climate ranges from subtropical in the north to tropical in the south. \\n\\n **Population:** \\n\\n *   With a population of over 23 million, it is the third-most populous state in the United States. \\n *   Miami-Dade is the most populous county. \\n\\n **History:** \\n\\n *   Various Native American tribes inhabited Florida for at least 14,000 years. \\n *   Juan Ponce de León, a Spanish explorer, discovered Florida in 1513. \\n *   St. Augustine, founded by the Spanish in 1565, is the oldest continuously settled city in the United States. \\n *   Florida was admitted as the 27th state to the United States on March 3, 1845. \\n\\n **Tourism and Recreation:** \\n\\n *   Florida is known for its beaches, amusement parks, warm climate and opportunities for nautical recreation. \\n *   The state has a large number of state parks, forests, national parks and preserves. \\n *   Tourism is a major industry in Florida. In 2024, Florida had a record of 143.0 million visitors. \\n *   Top origin countries for visitors to Florida in 2024 include Canada, Brazil, the United Kingdom, Colombia, and Mexico. \\n\\n **Unique Ecosystems and Wildlife:** \\n\\n *   Florida has unique ecosystems, including the Everglades National Park. \\n *  Everglades National Park is the only place where alligators and crocodiles coexist.\\n *   The state is home to diverse wildlife, including the American alligator, American crocodile, American flamingo, Florida panther, bottlenose dolphin, and manatee. \\n *   The Florida Reef is the only living coral barrier reef in the continental United States.\\n\"}], 'role': 'model'}, 'grounding_metadata': {'grounding_chunks': [{'web': {'domain': 'wikipedia.org', 'title': 'wikipedia.org', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG2gt5S-whbEFJBMH-UQZg21E2ZM-Eh9ObhHVuk9jCTTDo3WYxUMQZ0e9vMMbOrdqozJ8ye-Pb6VboahmoHnxeQD0hTefTi7yfRAS-u_PJwsKsmVJ9iYsAFXBMI19vj3DFNqDPS'}}, {'web': {'domain': 'wikipedia.org', 'title': 'wikipedia.org', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFN_uDKgUUJsLk5WgKa23N_qOwrciVpZOxO-JGrafe4LrjrFX_3cr9foMKY_eMxc5IejSYGCLs1cU6WJxi9xRayQWh_0gYbmsdmBUkQj7JuF9eX4QyuO-AqsmtI7MLut74='}}, {'web': {'domain': 'britannica.com', 'title': 'britannica.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyPz-RbMhje3fF-8DTTCRNQ-8PX4mw515qa1FmNfh8LAWGAm7igiVaG6s1kwDB83SF_BVRsCKqKDfm-B-ae6B4E3nu22kfMNtUntPkZLMthZEfCg_nrTE6swZmDfc7XJOeYbc='}}, {'web': {'domain': 'fl.gov', 'title': 'fl.gov', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEzCuh97wFklXeB2MALumkFSvLnv_pvDwDJBFf3WoVSPQrq9n-mxIc4ne777tAc5FNYOMYzSmfdlMAMI3oc8qCMSXGcOPYwr4RiD0wCwWM94Iw_y5PoBNoAVoSnRRWr-PA6uSgagO1FuQ=='}}, {'web': {'domain': 'visitflorida.com', 'title': 'visitflorida.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF7C82h5Ra74qKSkhxfJvjcwq6amB__vkrEjb3eOl1UoCCJm53wC6JTOStCsQUWh7ACLjW0X_lMqqG-Gs-_2F__92dHecXTMEF8kKnZDsJxEuxlpx_fXIwNXCsCFsq0Soc5rcAK1iBEYU0Kq9_2kC-hiiz5XTA6t_HyzGnL'}}, {'web': {'domain': 'rusticpathways.com', 'title': 'rusticpathways.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQ1lJeCElChn92XnqJIAS_CPHWcMfjv5y09VK-bUAylg5chnvQ7gWpLUcYoNOOpfriqpl0ZKTxKRqJPs-3OVUTe38s2vng5WYroXg5-RU4_VXjN362HLM0IwvF6INge61o5IeMXtt2nkiS4J4UghNHYNI='}}, {'web': {'domain': 'worldpopulationreview.com', 'title': 'worldpopulationreview.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0c_kq75lXiaZKj_ORTsYAaY8zr2XJTERzWL7-KmWMCIaBirGlynmyWjBkeXtbTRd3qpID8g0_J1isJTD9zCg5OHvzvTEyT9U_F0mMok7nCOvKy9mr4tH7lmTYuRJL6ls15F60SUKZJAWIyQ=='}}, {'web': {'domain': 'britannica.com', 'title': 'britannica.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFWpsmNoLc5yAnFMVVC06Fn4Q4C_cHP2o2Mt7q_T_Xse8KhcZ2lhdihBjdP5a9_MRYQws6cYBSjNsT8SmWREvrAo_yqiH-FrBxoVVfPr0zfpfbBXg5M5K-91gNpexySe-Iy5MdBwRFWL4zv3WCVcRXMUkb_lKLqg7lpVG5T4_usVgbWx9j7PTvzOn8FMA=='}}, {'web': {'domain': 'stateofflorida.com', 'title': 'stateofflorida.com', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGiaXErk27fd-J0fe5YEebsFmUlqeXKrVvPOYIm3g0cZ3u1g3kOJJ4h6eGUWJ97CYFST5o5VA703xORPBMV1mNMe0NBN7vvQvaozfnv58aMlt7wlRx0YBgYwYStYZe1OrM='}}, {'web': {'domain': 'visitflorida.org', 'title': 'visitflorida.org', 'uri': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGbPtL-wS-AIaMvCROSzfVIx6vVo2eyX4nCS0I6zueBibmaqFGGKpVGobKGWmJnsxHmKzOLKD0EHx5SzMqYun0hWzzEhES08PhGBnfkW4qm0ZnzZonaThJcpC95qrn1u3jB6EpjEdLYqULpZ-lEiJbBMZfEqYedBWw='}}], 'grounding_supports': [{'confidence_scores': [0.8984615, 0.9803153], 'grounding_chunk_indices': [0, 1], 'segment': {'end_index': 74, 'text': 'Florida is a state located in the Southeastern region of the United States'}}, {'confidence_scores': [0.8599041, 0.9290423], 'grounding_chunk_indices': [1, 0], 'segment': {'end_index': 298, 'start_index': 136, 'text': '*   It is a peninsula, surrounded by water on three sides: the Gulf of Mexico to the west, the Atlantic Ocean to the east, and the Straits of Florida to the south'}}, {'confidence_scores': [0.81424016, 0.89342487], 'grounding_chunk_indices': [1, 2], 'segment': {'end_index': 367, 'start_index': 302, 'text': '*   It shares a land border with Georgia and Alabama to the north'}}, {'confidence_scores': [0.0069578956, 0.119401604], 'grounding_chunk_indices': [1, 3], 'segment': {'end_index': 467, 'start_index': 371, 'text': '*   It has the longest coastline in the contiguous United States, with approximately 1,350 miles'}}, {'confidence_scores': [0.9769394, 0.08339082], 'grounding_chunk_indices': [4, 3], 'segment': {'end_index': 604, 'start_index': 523, 'text': 'The highest natural point is Britton Hill, which is only 345 feet above sea level'}}, {'confidence_scores': [0.9158936], 'grounding_chunk_indices': [1], 'segment': {'end_index': 692, 'start_index': 608, 'text': '*   It is the only state that borders both the Atlantic Ocean and the Gulf of Mexico'}}, {'confidence_scores': [0.9319935], 'grounding_chunk_indices': [1], 'segment': {'end_index': 730, 'start_index': 696, 'text': '*   The state spans two time zones'}}, {'confidence_scores': [0.8617664, 0.13757925], 'grounding_chunk_indices': [1, 5], 'segment': {'end_index': 788, 'start_index': 734, 'text': '*   It is the southernmost of the 48 contiguous states'}}, {'confidence_scores': [0.94219905], 'grounding_chunk_indices': [1], 'segment': {'end_index': 854, 'start_index': 792, 'text': '*   It is west of the Bahamas and about 90 miles north of Cuba'}}, {'confidence_scores': [0.9647477], 'grounding_chunk_indices': [4], 'segment': {'end_index': 922, 'start_index': 858, 'text': '*   Florida has more than 7,700 lakes and 11,000 miles of rivers'}}, {'confidence_scores': [0.95637304], 'grounding_chunk_indices': [1], 'segment': {'end_index': 1026, 'start_index': 943, 'text': \"*   Florida's climate ranges from subtropical in the north to tropical in the south\"}}, {'confidence_scores': [0.007318762], 'grounding_chunk_indices': [1], 'segment': {'end_index': 1148, 'start_index': 1050, 'text': '*   With a population of over 23 million, it is the third-most populous state in the United States'}}, {'confidence_scores': [0.06404353, 0.009842479], 'grounding_chunk_indices': [3, 6], 'segment': {'end_index': 1194, 'start_index': 1152, 'text': '*   Miami-Dade is the most populous county'}}, {'confidence_scores': [0.9513206, 0.005936864], 'grounding_chunk_indices': [1, 0], 'segment': {'end_index': 1293, 'start_index': 1215, 'text': '*   Various Native American tribes inhabited Florida for at least 14,000 years'}}, {'confidence_scores': [0.008381603, 0.007951716], 'grounding_chunk_indices': [7, 8], 'segment': {'end_index': 1368, 'start_index': 1297, 'text': '*   Juan Ponce de León, a Spanish explorer, discovered Florida in 1513'}}, {'confidence_scores': [0.00300094, 0.004248305], 'grounding_chunk_indices': [7, 3], 'segment': {'end_index': 1483, 'start_index': 1380, 'text': 'Augustine, founded by the Spanish in 1565, is the oldest continuously settled city in the United States'}}, {'confidence_scores': [0.0074251075, 0.9844156, 0.0086217], 'grounding_chunk_indices': [1, 8, 3], 'segment': {'end_index': 1567, 'start_index': 1487, 'text': '*   Florida was admitted as the 27th state to the United States on March 3, 1845'}}, {'confidence_scores': [0.01278999], 'grounding_chunk_indices': [1], 'segment': {'end_index': 1712, 'start_index': 1603, 'text': '*   Florida is known for its beaches, amusement parks, warm climate and opportunities for nautical recreation'}}, {'confidence_scores': [0.004633761], 'grounding_chunk_indices': [4], 'segment': {'end_index': 1802, 'start_index': 1716, 'text': '*   The state has a large number of state parks, forests, national parks and preserves'}}, {'confidence_scores': [0.00717869, 0.0048843394], 'grounding_chunk_indices': [9, 8], 'segment': {'end_index': 1905, 'start_index': 1850, 'text': 'In 2024, Florida had a record of 143.0 million visitors'}}, {'confidence_scores': [0.92753005], 'grounding_chunk_indices': [9], 'segment': {'end_index': 2030, 'start_index': 1909, 'text': '*   Top origin countries for visitors to Florida in 2024 include Canada, Brazil, the United Kingdom, Colombia, and Mexico'}}, {'confidence_scores': [0.0077778194, 0.010755235], 'grounding_chunk_indices': [1, 4], 'segment': {'end_index': 2147, 'start_index': 2074, 'text': '*   Florida has unique ecosystems, including the Everglades National Park'}}, {'confidence_scores': [0.93917805], 'grounding_chunk_indices': [5], 'segment': {'end_index': 2236, 'start_index': 2151, 'text': '*  Everglades National Park is the only place where alligators and crocodiles coexist'}}, {'confidence_scores': [0.013697837], 'grounding_chunk_indices': [1], 'segment': {'end_index': 2403, 'start_index': 2239, 'text': '*   The state is home to diverse wildlife, including the American alligator, American crocodile, American flamingo, Florida panther, bottlenose dolphin, and manatee'}}, {'confidence_scores': [0.0062021064, 0.2206197], 'grounding_chunk_indices': [1, 5], 'segment': {'end_index': 2498, 'start_index': 2407, 'text': '*   The Florida Reef is the only living coral barrier reef in the continental United States'}}], 'retrieval_metadata': {}, 'search_entry_point': {'rendered_content': '<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\"container\">\\n  <div class=\"headline\">\\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\\n    </svg>\\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\\n  </div>\\n  <div class=\"carousel\">\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpnSufeWahJWKOW2Qg9Y565oG6afEbZEUrpfegDz4drG6nj9RX3agNos-mZIYxj2EfA48IU9Bxy5qgYDn1r7WAKehhfS_tAQhY1NKy1ysMZFajEljwdzjFYztDSB0KdcV847aqRAGwzSRTKZG6u2yG-hm4hUexcvlipze0Md2gMEEdKYOLNXaEA19X0Xn6LSpR9Q==\">Florida tourism</a>\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEWCiE-QukJPxw7AKjFptuAYEvIfm_XxeLz09WGPsx7k3_6CCvFtr3lBb2F0xPAmsQz_6pZd9aeXulSKSaDMSvgReYMW6XQaVP-Rumh4f4--RTPtqky-PPSEuroSVKcq_O5XCuxJXv-jpc-psdEYC_HfSK7f-O66NcbycZ8DlJ7gwWl-RLkDWYyUlgOiwnu0sCn71RmTw==\">what is florida?</a>\\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYVkQtF2OBE0GDg9ira4AaODB9xtTvw1j7yjwyc-5rAB4oW2avO6gjE5vjuDaLK23ZeZWBouA6o_mRKMnez6-77DeIcTj5VOKV0HOLsnSdihu_fPDiVGvbXO7nrZBbYQ_02Mu7KOD4YLudz-mTWqJWqTxFKFARJomOuhF9RRrnzo9bc5BnKDiUy0wxJYwAC2I=\">Florida facts</a>\\n  </div>\\n</div>\\n'}, 'web_search_queries': ['what is florida?', 'Florida facts', 'Florida tourism']}, 'usage_metadata': {'candidates_token_count': 626, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 626}], 'prompt_token_count': 125, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 125}], 'total_token_count': 751, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-3d58f70b-590e-4fe2-aba6-4dab578329fe', 'author': 'external_google_search', 'id': '4cbc8bf5-f98b-4c53-b6b7-c141badf7bef', 'timestamp': 1752106671.60955}\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(root_agent)\n",
    "session = await run_session(content_text('Search the informatino about Florida.'), runner=runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo_JtQbFl_8k"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyo9EDRtmAFZ"
   },
   "source": [
    "### VertexAiExampleStore (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ATKaFEXWC11"
   },
   "source": [
    "### VertexAiRag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXC8WLhoiLZz",
    "outputId": "d06dd5da-68e8-4942-a2de-c8a1b064326c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in /usr/local/lib/python3.11/dist-packages (0.12.48)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.12)\n",
      "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.4)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.48 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.12.48)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.7.10)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.11)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.93.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (3.11.15)\n",
      "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.1.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.48->llama_index) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama_index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud==0.1.32 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.32)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.32->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.6.15)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (4.13.4)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.2.2)\n",
      "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (5.7.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.43)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama_index) (1.20.1)\n",
      "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama_index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama_index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama_index) (4.3.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.7)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama_index) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama_index) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama_index) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.48->llama_index) (0.16.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.48->llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.43 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.43)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama_index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama_index) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.48->llama_index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.48->llama_index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.48->llama_index) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.48->llama_index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.48->llama_index) (3.26.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.43->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.48->llama_index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (1.17.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama_index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama_index) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECXLwaYldZm8"
   },
   "outputs": [],
   "source": [
    "from google.adk.tools.retrieval.vertex_ai_rag_retrieval import VertexAiRagRetrieval\n",
    "from vertexai.preview import rag\n",
    "\n",
    "rag_retrieval = VertexAiRagRetrieval(\n",
    "    name='rag_retrieval',\n",
    "    description='Agent test case guidance',\n",
    "    rag_resources=[\n",
    "        rag.RagResource(\n",
    "            rag_corpus='projects/1096655024998/locations/us-central1/ragCorpora/4985766262475849728',\n",
    "        )\n",
    "    ],\n",
    "    vector_distance_threshold=0.8,\n",
    ")\n",
    "\n",
    "rag_agent= Agent(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    name='rag_agent',\n",
    "    instruction=\"\"\"You are an agent to test the rag retrieval tool5.\"\"\",\n",
    "    tools=[rag_retrieval],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjBzpDuSdeGL",
    "outputId": "9f8074e9-b16c-4671-9d1c-90f62ab79ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the agent test case guidance\n",
      "----------------------------------\n",
      "Author: rag_agent\n",
      "Content Text: The agent test case guidance is based on a phased approach focusing on blackbox integration testing that hits the real Gemini endpoint. The testing plan includes single-agent tests with tools like roll_die() and check_prime() functions, testing for different flow combinations (SingleFlow, SequentialFlow, AutoFlow), context operations, callbacks, artifacts, event streaming, function calling (parallel, async), and both 1p (P0) and 3p (P2) tools. The current testing plan focuses on launch blockers. Future testing plans include Streamlit UI testing and CLI tool testing.\n",
      "Event: {'content': {'parts': [{'text': 'The agent test case guidance is based on a phased approach focusing on blackbox integration testing that hits the real Gemini endpoint. The testing plan includes single-agent tests with tools like roll_die() and check_prime() functions, testing for different flow combinations (SingleFlow, SequentialFlow, AutoFlow), context operations, callbacks, artifacts, event streaming, function calling (parallel, async), and both 1p (P0) and 3p (P2) tools. The current testing plan focuses on launch blockers. Future testing plans include Streamlit UI testing and CLI tool testing.'}], 'role': 'model'}, 'grounding_metadata': {'grounding_chunks': [{'retrieved_context': {'rag_chunk': {'text': 'Agent SDK2.0 Testing Plan\\r\\nAuthor: Hangfei Lin Ethan Bao\\r\\nTesting Strategy\\r\\nWe are taking a phased approach. For the \\uffferst phase, we are focusing on blackbox integration\\r\\ntesting that hits the real Gemini endpoint. We will evaluate tool trajectory and \\ufffenal response\\r\\ncoherence.\\r\\nTesting Plan\\r\\nIntegration Tests\\r\\nCurrent Testing Plan\\r\\nThe following tests are launch blockers.\\r\\nTest Scenario Details Proposal\\r\\nTesting Setup\\r\\nPOC Status\\r\\nSingle-agent Test a single\\r\\nagent setup\\r\\nwith a few tools\\r\\nA roll-die agent\\r\\nwith roll_die()\\r\\nand\\r\\ncheck_prime()\\r\\nfunction.\\r\\nTest for all \\ufffeows Test SingleFlow,\\r\\nSequentialFlow,\\r\\nAutoFlow\\r\\nTest for all \\ufffeow\\r\\ncombinations\\r\\nTest an agent\\r\\nthat combines\\r\\nmultiple\\r\\ndi\\ufffeerent \\ufffeows\\r\\nTest for all context\\r\\noperations\\r\\nTest call backsTest for artifacts\\r\\nevent streaming (yields)\\r\\nfunction calling\\r\\n● parallel\\r\\n● async\\r\\nTools\\r\\n● 1p tools(P0)\\r\\n● 3p tools(P2)\\r\\nKe Chang\\r\\nexamplestore\\r\\nSession and Events Shangjie Chen\\r\\nNL planner\\r\\nFuture Testing Plan\\r\\nTest Scenario Details Proposal\\r\\nTesting Setup\\r\\nPOC Status\\r\\nTBD\\r\\nStremalit UI\\r\\ntesting\\r\\nCLI tool testing'}, 'text': 'Agent SDK2.0 Testing Plan\\r\\nAuthor: Hangfei Lin Ethan Bao\\r\\nTesting Strategy\\r\\nWe are taking a phased approach. For the �rst phase, we are focusing on blackbox integration\\r\\ntesting that hits the real Gemini endpoint. We will evaluate tool trajectory and �nal response\\r\\ncoherence.\\r\\nTesting Plan\\r\\nIntegration Tests\\r\\nCurrent Testing Plan\\r\\nThe following tests are launch blockers.\\r\\nTest Scenario Details Proposal\\r\\nTesting Setup\\r\\nPOC Status\\r\\nSingle-agent Test a single\\r\\nagent setup\\r\\nwith a few tools\\r\\nA roll-die agent\\r\\nwith roll_die()\\r\\nand\\r\\ncheck_prime()\\r\\nfunction.\\r\\nTest for all �ows Test SingleFlow,\\r\\nSequentialFlow,\\r\\nAutoFlow\\r\\nTest for all �ow\\r\\ncombinations\\r\\nTest an agent\\r\\nthat combines\\r\\nmultiple\\r\\ndi�erent �ows\\r\\nTest for all context\\r\\noperations\\r\\nTest call backsTest for artifacts\\r\\nevent streaming (yields)\\r\\nfunction calling\\r\\n● parallel\\r\\n● async\\r\\nTools\\r\\n● 1p tools(P0)\\r\\n● 3p tools(P2)\\r\\nKe Chang\\r\\nexamplestore\\r\\nSession and Events Shangjie Chen\\r\\nNL planner\\r\\nFuture Testing Plan\\r\\nTest Scenario Details Proposal\\r\\nTesting Setup\\r\\nPOC Status\\r\\nTBD\\r\\nStremalit UI\\r\\ntesting\\r\\nCLI tool testing', 'title': 'Agent_test_plan.pdf', 'uri': 'gs://agent_rag_test/Agent_test_plan.pdf'}}], 'grounding_supports': [{'confidence_scores': [0.91596], 'grounding_chunk_indices': [0], 'segment': {'end_index': 135, 'text': 'The agent test case guidance is based on a phased approach focusing on blackbox integration testing that hits the real Gemini endpoint.'}}, {'confidence_scores': [0.9501887], 'grounding_chunk_indices': [0], 'segment': {'end_index': 447, 'start_index': 136, 'text': 'The testing plan includes single-agent tests with tools like roll_die() and check_prime() functions, testing for different flow combinations (SingleFlow, SequentialFlow, AutoFlow), context operations, callbacks, artifacts, event streaming, function calling (parallel, async), and both 1p (P0) and 3p (P2) tools.'}}, {'confidence_scores': [0.9297404], 'grounding_chunk_indices': [0], 'segment': {'end_index': 500, 'start_index': 448, 'text': 'The current testing plan focuses on launch blockers.'}}, {'confidence_scores': [0.97116524], 'grounding_chunk_indices': [0], 'segment': {'end_index': 572, 'start_index': 501, 'text': 'Future testing plans include Streamlit UI testing and CLI tool testing.'}}], 'retrieval_queries': ['agent test case guidance']}, 'usage_metadata': {'candidates_token_count': 119, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 119}], 'prompt_token_count': 34, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 34}], 'total_token_count': 153, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-51252832-3d9b-4ee6-9215-735273aae154', 'author': 'rag_agent', 'id': '83af4772-58d6-40dc-9450-e987408a934c', 'timestamp': 1752106686.487655}\n",
      "----------------------------------\n",
      "Expected output: something similar to below\n",
      "Content Text: The agent test case guidance outlines a phased testing approach for Agent SDK 2.0, focusing on ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner = create_runner(rag_agent)\n",
    "session = await run_session(content_text('What is the agent test case guidance'), runner=runner)\n",
    "\n",
    "print(\"\"\"Expected output: something similar to below\n",
    "Content Text: The agent test case guidance outlines a phased testing approach for Agent SDK 2.0, focusing on ...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4pf_L5miq5I"
   },
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFP3OFrpiuG0"
   },
   "source": [
    "### ADK Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgFPozeti3SP"
   },
   "source": [
    "#### Prepare\n",
    "\n",
    "Prerequist: create a free account in [NGROK dashboard](https://dashboard.ngrok.com/), get the auth token and put in colab secret as `NGROK_TOKEN`.\n",
    "\n",
    "Steps\n",
    "\n",
    "* Install required packages\n",
    "* Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFJwfGrNiwHX",
    "outputId": "9776ab83-78ac-49a8-d17c-a134fc60244a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.12\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "WM_XF-C4jHuR",
    "outputId": "8d2c2f53-856c-47b8-e5a4-47345effb5f1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# from pyngrok import ngrok\n",
    "# import nest_asyncio\n",
    "\n",
    "# ngrok.set_auth_token(userdata.get('NGROK_TOKEN'))\n",
    "\n",
    "# # Allow nested event loops (Colab needs this)\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBh27Btwi-kc"
   },
   "source": [
    "#### Write Agent Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6xGc5OAdvuf"
   },
   "outputs": [],
   "source": [
    "!mkdir -p agents/my_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ekxFOcGdpjn"
   },
   "outputs": [],
   "source": [
    "%%writefile agents/my_agent/__init__.py\n",
    "\n",
    "from . import agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLvZ5rLKdYz8"
   },
   "outputs": [],
   "source": [
    "%%writefile agents/my_agent/agent.py\n",
    "\n",
    "import random\n",
    "\n",
    "from google.adk import Agent\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "def roll_die(sides: int) -> int:\n",
    "  \"\"\"Roll a die and return the rolled result.\n",
    "\n",
    "  Args:\n",
    "    sides: The integer number of sides the die has.\n",
    "\n",
    "  Returns:\n",
    "    An integer of the result of rolling the die.\n",
    "  \"\"\"\n",
    "  return random.randint(1, sides)\n",
    "\n",
    "\n",
    "async def check_prime(nums: list[int]) -> str:\n",
    "  \"\"\"Check if a given list of numbers are prime.\n",
    "\n",
    "  Args:\n",
    "    nums: The list of numbers to check.\n",
    "\n",
    "  Returns:\n",
    "    A str indicating which number is prime.\n",
    "  \"\"\"\n",
    "  primes = set()\n",
    "  for number in nums:\n",
    "    number = int(number)\n",
    "    if number <= 1:\n",
    "      continue\n",
    "    is_prime = True\n",
    "    for i in range(2, int(number**0.5) + 1):\n",
    "      if number % i == 0:\n",
    "        is_prime = False\n",
    "        break\n",
    "    if is_prime:\n",
    "      primes.add(number)\n",
    "  return (\n",
    "      'No prime numbers found.'\n",
    "      if not primes\n",
    "      else f\"{', '.join(str(num) for num in primes)} are prime numbers.\"\n",
    "  )\n",
    "\n",
    "\n",
    "root_agent = Agent(\n",
    "    model='gemini-2.0-flash-exp',\n",
    "    name='data_processing_agent',\n",
    "    description=(\n",
    "        'hello world agent that can roll a dice of 8 sides and check prime'\n",
    "        ' numbers.'\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "      You roll dice and answer questions about the outcome of the dice rolls.\n",
    "      You can roll dice of different sizes.\n",
    "      You can use multiple tools in parallel by calling functions in parallel(in one request and in one round).\n",
    "      It is ok to discuss previous dice roles, and comment on the dice rolls.\n",
    "      When you are asked to roll a die, you must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.\n",
    "      You should never roll a die on your own.\n",
    "      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string.\n",
    "      You should not check prime numbers before calling the tool.\n",
    "      When you are asked to roll a die and check prime numbers, you should always make the following two function calls:\n",
    "      1. You should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.\n",
    "      2. After you get the function response from roll_die tool, you should call the check_prime tool with the roll_die result.\n",
    "        2.1 If user asks you to check primes based on previous rolls, make sure you include the previous rolls in the list.\n",
    "      3. When you respond, you must include the roll_die result from step 1.\n",
    "      You should always perform the previous 3 steps when asking for a roll and checking prime numbers.\n",
    "      You should not rely on the previous history on prime results.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        roll_die,\n",
    "        check_prime,\n",
    "    ],\n",
    "    # planner=BuiltInPlanner(\n",
    "    #     thinking_config=types.ThinkingConfig(\n",
    "    #         include_thoughts=True,\n",
    "    #     ),\n",
    "    # ),\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(  # avoid false alarm about rolling dice.\n",
    "                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                threshold=types.HarmBlockThreshold.OFF,\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKUTZd7sjTV4"
   },
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2Wc-0duhosX"
   },
   "outputs": [],
   "source": [
    "public_url = ngrok.connect(8000)\n",
    "print(f\"FastAPI app exposed at: {public_url}\")\n",
    "!adk web agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvJjVcBwq6tR"
   },
   "source": [
    "## Utility features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNOHca3Xd66E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkay5rKSrEZA"
   },
   "source": [
    "### Cloud Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hgf13VI6PmoP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter\n",
    "from opentelemetry.sdk.trace import export\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "\n",
    "provider = TracerProvider()\n",
    "processor = export.BatchSpanProcessor(\n",
    "    CloudTraceSpanExporter(project_id=GOOGLE_CLOUD_PROJECT)\n",
    ")\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "\n",
    "def roll_die(sides: int) -> int:\n",
    "  \"\"\"Roll a die and return the rolled result.\n",
    "\n",
    "  Args:\n",
    "    sides: The integer number of sides the die has.\n",
    "\n",
    "  Returns:\n",
    "    An integer of the result of rolling the die.\n",
    "  \"\"\"\n",
    "  return random.randint(1, sides)\n",
    "\n",
    "dice_agent = Agent(\n",
    "    name='dice_agent',\n",
    "    model='gemini-2.0-flash-exp',\n",
    "    instruction='Just roll a dice of 8 sides when being asked to roll a die.',\n",
    "    tools=[roll_die],\n",
    ")\n",
    "\n",
    "runner = create_runner(dice_agent)\n",
    "\n",
    "session = await run_session(content_text('Roll a dice for me'), runner=runner)\n",
    "\n",
    "provider.force_flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyjk9C-pyF8r"
   },
   "source": [
    "# Exploratory Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s13Yvj-8ySLP"
   },
   "outputs": [],
   "source": [
    "# Agent define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx9iumygyUMo"
   },
   "outputs": [],
   "source": [
    "# runner with test prompt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py312",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "conda-base-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
