{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTsEHA-Xb10j"
   },
   "source": [
    "# ADK 101 in 45min\n",
    "\n",
    "\n",
    "Where to test:\n",
    "- stdout output\n",
    "- `adk web` as UI -- very nice visualizations\n",
    "\n",
    "Pre-caution:\n",
    "- ADK is still under development. The official launch is early April. This training is intended to provide hands-on experience with the Agent Development Kit (ADK) and its foundational concepts.\n",
    "\n",
    "\n",
    "Documents \n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/adk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9AedAKNb_1h"
   },
   "source": [
    "# Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fYhFnbLqcGWM",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opentelemetry-sdk in /home/jupyter/.local/lib/python3.10/site-packages (1.33.1)\n",
      "Collecting opentelemetry-sdk\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: opentelemetry-api in /home/jupyter/.local/lib/python3.10/site-packages (1.33.1)\n",
      "Collecting opentelemetry-api\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform[all] in /home/jupyter/.local/lib/python3.10/site-packages (1.98.0)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk) (4.13.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api) (7.2.1)\n",
      "\u001b[33mWARNING: google-cloud-aiplatform 1.98.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (5.29.4)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (3.34.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (2.0.7)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (1.21.1)\n",
      "Requirement already satisfied: pydantic<3 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (2.11.7)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[all]) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[all]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[all]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[all]) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[all]) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[all]) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform[all]) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform[all]) (1.6.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (4.9.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (8.5.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (15.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api) (3.21.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jupyter/.local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform[all]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform[all]) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform[all]) (1.26.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform[all]) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform[all]) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[all]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[all]) (2.4.0)\n",
      "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Installing collected packages: opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.33.1\n",
      "    Uninstalling opentelemetry-api-1.33.1:\n",
      "      Successfully uninstalled opentelemetry-api-1.33.1\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.54b1\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.54b1:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.54b1\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.33.1\n",
      "    Uninstalling opentelemetry-sdk-1.33.1:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.33.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-instrumentation 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.55b1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.33.1 requires opentelemetry-sdk~=1.33.1, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.33.1 requires opentelemetry-sdk~=1.33.1, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
      "opentelemetry-instrumentation-asgi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.55b1 which is incompatible.\n",
      "opentelemetry-instrumentation-fastapi 0.54b1 requires opentelemetry-semantic-conventions==0.54b1, but you have opentelemetry-semantic-conventions 0.55b1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install google_adk \n",
    "# !pip install -q --upgrade google-cloud-discoveryengine\n",
    "# !pip install google-adk\n",
    "# !pip install google-genai\n",
    "# !pip install pydantic\n",
    "!pip install --upgrade opentelemetry-sdk opentelemetry-api \"google-cloud-aiplatform[all]\"\n",
    "#-0.0.2.dev20250324+739344859-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart current runtime\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel.\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<b>NOTE:</b> Only restart the current runtime if you installed libraries. If you did not install new libraries, you do not need to restart the kernel.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "# import time\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qhUqPpmKcNxR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: my-project-0004-346516\n",
      "Project Region: us-central1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Cloud project id.\n",
    "PROJECT_IDS = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_IDS[0]  # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID:\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"TRUE\" # Use Vertex AI API\n",
    "# [your-project-id]\n",
    "\n",
    "# Print project and location details\n",
    "print(f\"Project ID:\", PROJECT_ID)\n",
    "print(f\"Project Region:\", LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my-project-0004-346516-sm already exists.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "GCS_BUCKET_LOCATION = LOCATION\n",
    "UNIQUE_PREFIX = 'sm' #\"<REPLACE_WITH_PREFIX>\"\n",
    "\n",
    "GCS_BUCKET_NAME = f\"{PROJECT_ID}-{UNIQUE_PREFIX}\"\n",
    "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n",
    "\n",
    "bucket = storage.Bucket(client, GCS_BUCKET_NAME)\n",
    "\n",
    "if bucket.exists()==False:\n",
    "    # Create a Cloud Storage Bucket\n",
    "    !gcloud storage buckets create $GCS_BUCKET_URI --location=$GCS_BUCKET_LOCATION\n",
    "\n",
    "else:    \n",
    "    print(f\"\\n{GCS_BUCKET_NAME} already exists.\")\n",
    "    \n",
    "def gcs_file(blob_name):\n",
    "    return bucket.blob(blob_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai import agent_engines\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "LOCATION = \"us-central1\" #@param {type:\"string\"}\n",
    "STAGING_BUCKET = GCS_BUCKET_URI\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jRGwZBG9dtLO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gcloud storage ls gs://adk_training/sdk\n",
    "# !gcloud storage cp gs://adk_training/sdk/google_adk-0.0.2.dev20250324+739344859-py3-none-any.whl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.agents import BaseAgent, LlmAgent, Agent, SequentialAgent, LoopAgent, ParallelAgent\n",
    "from google.adk.agents.readonly_context import ReadonlyContext\n",
    "from google.adk.tools import ToolContext, LongRunningFunctionTool\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.sessions import Session\n",
    "from google.adk.events import Event\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOPsVd4veC2I"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mT_mZYtpeA5W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def pprint_events(events):\n",
    "    '''Pretty print of events generated by ADK runner'''\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _, event in enumerate(events):\n",
    "        is_final_response = event.is_final_response()\n",
    "        function_calls = event.get_function_calls()\n",
    "        function_responses = event.get_function_responses()\n",
    "\n",
    "        try:\n",
    "            agent_res = json.loads(event.content.model_dump_json(indent=2, exclude_none=True))\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error parsing event content: {e}\")\n",
    "            continue\n",
    "\n",
    "        if is_final_response:\n",
    "            final_response = event.content.parts[0].text if event.content.parts else \"No content available\"\n",
    "            elapsed_time_ms = round((time.time() - start_time) * 1000, 3)\n",
    "            print(f'>>> Final Response ({elapsed_time_ms} ms):\\n{final_response}')\n",
    "            print(\"-\" * 30)\n",
    "        elif function_calls:\n",
    "            print('+++ Function Calls:')\n",
    "            for function_call in function_calls:\n",
    "                print(f\"Function Name: {function_call.name}, Args: {function_call.args}\")\n",
    "        elif function_responses:\n",
    "            print('--- Function Responses:')\n",
    "            for function_response in function_responses:\n",
    "                response_details = function_response.response\n",
    "                recommended_list = list(response_details.values()) if response_details else []\n",
    "                print(f\"Function Name: {function_response.name}\")\n",
    "                print(f\"Function Results: {json.dumps(recommended_list)}\")\n",
    "        else:\n",
    "            print('No function calls or responses available.')\n",
    "            print(f\"Agent Response: {agent_res}\")\n",
    "\n",
    "    elapsed_time_ms = round((time.time() - start_time) * 1000, 3)\n",
    "    print(f\"Total elapsed time: {elapsed_time_ms} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "\n",
    "APP_NAME = 'test_app'\n",
    "USER_ID = 'test_user'\n",
    "\n",
    "def create_runner(agent: BaseAgent):\n",
    "    return InMemoryRunner(agent, app_name=APP_NAME)\n",
    "\n",
    "def _content_to_text(content: types.Content | None) -> str:\n",
    "    if not content or not content.parts:\n",
    "        return ''\n",
    "    return ''.join([p.text or '' for p in content.parts])\n",
    "\n",
    "def print_event(event: Event):\n",
    "    print(f'Author: {event.author}')\n",
    "    print(f'Content Text: {_content_to_text(event.content)}')\n",
    "    print(f'Event: {event.model_dump(exclude_none=True, exclude_defaults=True)}')\n",
    "\n",
    "async def run_session(new_message: types.Content, *, runner: Runner, session: Optional[Session] = None, state: Optional[dict[str, Any]] = None) -> Session:\n",
    "    if session is None:\n",
    "        session = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, state=state)\n",
    "        \n",
    "    print(f'User: {_content_to_text(new_message)}')\n",
    "    print('----------------------------------')\n",
    "    async for e in runner.run_async(user_id=USER_ID, session_id=session.id, new_message=new_message):\n",
    "        print_event(e)\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    session = runner.session_service.get_session(app_name=session.app_name, user_id=session.user_id, session_id=session.id)\n",
    "    return session\n",
    "\n",
    "def content_text(msg: str) -> types.Content:\n",
    "    return types.UserContent(parts=[types.Part(text=msg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HVKgWyHekT0",
    "tags": []
   },
   "source": [
    "# Hello world!\n",
    "\n",
    "Concepts:\n",
    "\n",
    "- Agent - Starts as a wrapper of LLM that can decide actions and interact with external world (other agents, tools)\n",
    "- Session - Maintains the state of one invocation. (chat log / events/ etc)\n",
    "- Runner - The orchestration layer of agents. The \"state machine\". Runner drives agents to move the states of a session forward.\n",
    "\n",
    "Use case:\n",
    "- An agent that says hello word in a random language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "56FKIJsAgJJs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "logging.getLogger('google_genai.types').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.generativeai.types.content_types') # Suppress harmless warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uUdAMMPAea2-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constant\n",
    "APP_NAME = \"hello_world_example\"\n",
    "USER_ID = \"user12345\"\n",
    "SESSION_ID = \"session12345\"\n",
    "AGENT_NAME = \"hello_word_agent\"\n",
    "MODEL = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK3-ZOuXLXIg"
   },
   "source": [
    "**Instructions:** Start by defining what your agent should do using simple natural language instructions. This provides a very straightforward way to customize agent actions without needing to compose complex chains or graphs. You can even reference context like user information and current time within these instructions, which will be filled in at runtime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Sessions:** The Agent Framework handles session management for you, allowing you to focus on building your agent's logic. You can use the provided BaseSession interface with managed storage or easily plug in your own. The InMemorySession is available for rapid development and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tIdaHSS5ShDb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agent\n",
    "hello_world_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"hello_world_agent\",\n",
    "    description=\"An agent that says 'hello world'\",\n",
    "    instruction=\"\"\"You always say 'hello world' to the user, and nothing else.\n",
    "    Output 'hello world' in a random language.\n",
    "    Put the language in brackets.\n",
    "\n",
    "    Example Output 1:\n",
    "    hello world (English)\n",
    "\n",
    "    Example Output 2:\n",
    "    你好，世界 (Chinese)\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Session and Runner\n",
    "session_service = InMemorySessionService()\n",
    "session = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "runner = Runner(agent=hello_world_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "# Agent Interaction\n",
    "def call_agent(runner, query):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mfcIGw-SiZO",
    "outputId": "82517754-4b1f-4529-c096-dc026a091d4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (_asyncio_thread_main):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/adk/runners.py\", line 143, in _asyncio_thread_main\n",
      "    asyncio.run(_invoke_run_async())\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 649, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/adk/runners.py\", line 131, in _invoke_run_async\n",
      "    async for event in self.run_async(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/adk/runners.py\", line 184, in run_async\n",
      "    raise ValueError(f'Session not found: {session_id}')\n",
      "ValueError: Session not found: session12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 5.273 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, \"hello\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnRr7SIkdBhv",
    "outputId": "a8650181-9109-48a8-999e-d5105ff7f4b7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object InMemorySessionService.create_session at 0x7faae4939e00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AJk0y2Z5dhPb",
    "outputId": "1a11ec42-57bb-4c3e-ca57-30c9bae4f602",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnOHrq2odid0",
    "outputId": "e1c9fc5a-93f8-4108-d938-1b8edf6f0bcb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object InMemorySessionService.list_sessions at 0x7faae493a490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_service.list_sessions(app_name=APP_NAME, user_id=USER_ID)\n",
    "\n",
    "#TypeError: InMemorySessionService.list_sessions() missing 2 required keyword-only arguments: 'app_name' and 'user_id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6V8U37pdtBw",
    "outputId": "a79761d7-1748-44f4-bdad-b94ca8ad1c17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pprint(session_service.sessions[APP_NAME][USER_ID][SESSION_ID].events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA2NbUZHhpK4"
   },
   "source": [
    "# Multi turn conversation\n",
    "\n",
    "Concepts:\n",
    "\n",
    "- Event(s)\n",
    "- Session\n",
    "- SessionService: sessions[app][user][session]\n",
    "\n",
    "Use case:\n",
    "\n",
    "- An agent that tries to know your name and send hello USERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM8NxYwZhhze",
    "outputId": "6adf9764-5762-4455-9dfc-906a28a293d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: [Event(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"Hello there!  Before we begin, could I please ask for your name?  It doesn't have to be your full name – a first name, nickname, or whatever you're comfortable sharing will do.  Knowing your name will help me personalize our interaction.\\n\")], role='model'), grounding_metadata=None, partial=None, turn_complete=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=56, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=56)], prompt_token_count=93, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=93)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=149, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>), invocation_id='e-3e7a3cc1-8fa9-43b5-84d5-d7adbf096f74', author='hello_name_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}), long_running_tool_ids=None, branch=None, id='sFKJ19tJ', timestamp=1750686326.511764)]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.genai import types\n",
    "# from google.adk import Agent, Runner, InMemorySessionService\n",
    "\n",
    "# Constants\n",
    "APP_NAME = \"hello_name_example\"\n",
    "USER_ID = \"user12345\"\n",
    "SESSION_ID = \"session12345\"\n",
    "AGENT_NAME = \"hello_name_agent\"\n",
    "MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# Agent\n",
    "hello_name_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=AGENT_NAME,\n",
    "    description=\"An agent that says 'hello USERNAME'\",\n",
    "    instruction=\"\"\"\n",
    "    You need to first ask the user's name.\n",
    "    Try best to convince the user to give you a name, let it be first name, last name, or nick name.\n",
    "    Once you get the user's name, say 'hello USERNAME'.\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # Session and Runner\n",
    "    session_service = InMemorySessionService()\n",
    "    session = await session_service.create_session(\n",
    "        app_name=APP_NAME, \n",
    "        user_id=USER_ID, \n",
    "        session_id=SESSION_ID\n",
    "    )\n",
    "    runner = Runner(agent=hello_name_agent, app_name=APP_NAME, session_service=session_service)\n",
    "    \n",
    "    # Agent Interaction - NO AWAIT HERE, runner.run() is synchronous\n",
    "    def call_agent(runner, session, query):\n",
    "        content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "        events = runner.run(  # NO AWAIT HERE\n",
    "            user_id=session.user_id, \n",
    "            session_id=session.id, \n",
    "            new_message=content\n",
    "        )\n",
    "        return events\n",
    "    \n",
    "    events = call_agent(runner, session, \"hello\")  # NO AWAIT HERE\n",
    "    \n",
    "    # Convert generator to list to see all events\n",
    "    events_list = list(events)\n",
    "    print(\"Events:\", events_list)\n",
    "    \n",
    "    return events_list\n",
    "\n",
    "# Run the async function\n",
    "events = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.046 ms):\n",
      "I understand you may be hesitant to share your name, but it would help me to personalize our interaction.  Even a nickname will do!  Knowing your name, even just a part of it, allows me to address you more appropriately and makes our conversation feel a bit more friendly.  Would you be willing to share at least a portion of your name with me?\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.173 ms\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.genai import types\n",
    "# from google.genai.adk import Agent, Runner, InMemorySessionService\n",
    "\n",
    "# Constants\n",
    "APP_NAME = \"hello_name_example\"\n",
    "USER_ID = \"user12345\"\n",
    "SESSION_ID = \"session12345\"\n",
    "AGENT_NAME = \"hello_name_agent\"\n",
    "MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# Agent\n",
    "hello_name_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=AGENT_NAME,\n",
    "    description=\"An agent that says 'hello USERNAME'\",\n",
    "    instruction=\"\"\"\n",
    "    You need to first ask the user's name.\n",
    "    Try best to convince the user to give you a name, let it be first name, last name, or nick name.\n",
    "    Once you get the user's name, say 'hello USERNAME'.\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        max_output_tokens=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Setup everything\n",
    "session_service = InMemorySessionService()\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME, \n",
    "    user_id=USER_ID, \n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "runner = Runner(agent=hello_name_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "# Agent interaction function\n",
    "def call_agent(runner, session, query):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "    events = runner.run(\n",
    "        user_id=session.user_id, \n",
    "        session_id=session.id, \n",
    "        new_message=content\n",
    "    )\n",
    "    return list(events)  # Convert generator to list immediately\n",
    "\n",
    "# Test the agent\n",
    "events = call_agent(runner, session, \"I don't tell you my name\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFLtRT_IiRhC",
    "outputId": "ed318530-bff1-4d42-ba19-50b3dc899e02",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.049 ms):\n",
      "Okay, I respect your decision not to share your name.  Let's proceed without it.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.173 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, session, \"I don't tell you my name\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCuD8S4MiVOs",
    "outputId": "cb8a7835-d1fa-4ea1-efa7-cb65e950a569",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.045 ms):\n",
      "My internal name is hello_name_agent.  My description is \"An agent that says 'hello USERNAME'\".\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.146 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, session, \"what is your name?\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5TlnG3EiXsY",
    "outputId": "02979dbf-c28c-4b01-89d5-ec38e50bbcf6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.044 ms):\n",
      "Hello Amir!\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.165 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, session, \"my name is Amir\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_rEYbAPibZ2",
    "outputId": "709ed2eb-03af-460c-a434-563934461505",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.043 ms):\n",
      "Your name is Amir.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.146 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, session, \"what is my name?\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSrpZP1_g7EK"
   },
   "source": [
    "## Switch session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "T45N77TCg9EG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID + '-new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6baZcd68hB_C",
    "outputId": "9af983da-927f-4560-f9b7-80a80eed4d7d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.047 ms):\n",
      "Hello!  I need your name to properly greet you.  It can be your first name, last name, nickname – whatever you'd like me to call you.  Could you please tell me your name?\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.16 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, new_session, \"what is my name?\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxBoNqeWhFov",
    "outputId": "4d271815-4143-433e-e02d-16f59f649a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.068 ms):\n",
      "Your name is Amir.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.189 ms\n"
     ]
    }
   ],
   "source": [
    "events = call_agent(runner, session, \"what is my name?\")\n",
    "pprint_events(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0onZ7XLEioW_"
   },
   "source": [
    "# Use Tool\n",
    "\n",
    "**Function Tools:** To extend your agent's capabilities, you can provide it with Python functions as tools. When the agent determines it needs to perform a specific action, it can automatically call these functions\n",
    "\n",
    "Concept:\n",
    "- Tool (Python function) -- the experience of tool calling by agent (by LLM) or by human (from Python) are the same. Easy to test.\n",
    "\n",
    "Use case:\n",
    "- Simple math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "C6Oh_PgBhhkA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add(numbers: list[int]) -> int:\n",
    "  \"\"\"Calculates the sum of a list of integers.\n",
    "\n",
    "    This function takes a list of integers as input and returns the sum of all\n",
    "    the elements in the list.  It uses the built-in `sum()` function for\n",
    "    efficiency.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be added.\n",
    "\n",
    "    Returns:\n",
    "        The sum of the integers in the input list.  Returns 0 if the input\n",
    "        list is empty.\n",
    "\n",
    "    Examples:\n",
    "        add([1, 2, 3]) == 6\n",
    "        add([-1, 0, 1]) == 0\n",
    "        add([]) == 0\n",
    "    \"\"\"\n",
    "  return sum(numbers)\n",
    "\n",
    "def subtract(numbers: list[int]) -> int:\n",
    "    \"\"\"Subtracts numbers in a list sequentially from left to right.\n",
    "\n",
    "    This function performs subtraction on a list of integers, applying the\n",
    "    subtraction operation from left to right.  For example, given the list\n",
    "    [10, 2, 5], the function will calculate 10 - 2 - 5.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be subtracted.\n",
    "\n",
    "    Returns:\n",
    "        The result of the sequential subtraction as an integer. Returns 0 if the input list is empty.\n",
    "\n",
    "    Examples:\n",
    "        subtract([10, 2, 5]) == 3  # (10 - 2) - 5 = 8 - 5 = 3\n",
    "        subtract([10, 2]) == 8      # 10 - 2 = 8\n",
    "        subtract([]) == 0\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        return 0  # Handle empty list\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result -= num\n",
    "    return result\n",
    "\n",
    "def multiply(numbers: list[int]) -> int:\n",
    "  \"\"\"Calculates the product of a list of integers.\n",
    "\n",
    "    This function takes a list of integers as input and returns the product of all\n",
    "    the elements in the list. It iterates through the list, multiplying each\n",
    "    number with the accumulated product.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be multiplied.\n",
    "\n",
    "    Returns:\n",
    "        The product of the integers in the input list. Returns 1 if the input\n",
    "        list is empty.\n",
    "\n",
    "    Examples:\n",
    "        multiply([2, 3, 4]) == 24  # 2 * 3 * 4 = 24\n",
    "        multiply([1, -2, 5]) == -10 # 1 * -2 * 5 = -10\n",
    "        multiply([]) == 1\n",
    "    \"\"\"\n",
    "  product = 1\n",
    "  for num in numbers:\n",
    "    product *= num\n",
    "  return product\n",
    "\n",
    "def divide(numbers: list[int]) -> float:  # Use float for division\n",
    "    \"\"\"Divides numbers in a list sequentially from left to right.\n",
    "\n",
    "    This function performs division on a list of integers, applying the division\n",
    "    operation from left to right.  For example, given the list [10, 2, 5], the\n",
    "    function will calculate 10 / 2 / 5.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be divided.\n",
    "\n",
    "    Returns:\n",
    "        The result of the sequential division as a float.\n",
    "\n",
    "    Raises:\n",
    "        ZeroDivisionError: If any number in the list *after* the first element\n",
    "                           is zero, a ZeroDivisionError is raised.  Division by\n",
    "                           zero is not permitted.\n",
    "\n",
    "    Returns:\n",
    "        float: The result of the division. Returns 0.0 if the input list is empty.\n",
    "\n",
    "    Examples:\n",
    "        divide([10, 2, 5]) == 1.0  # (10 / 2) / 5 = 5 / 5 = 1.0\n",
    "        divide([10, 2]) == 5.0      # 10 / 2 = 5.0\n",
    "        divide([10, 0, 5])  # Raises ZeroDivisionError\n",
    "        divide([]) == 0.0\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        return 0.0 # Handle empty list\n",
    "    if 0 in numbers[1:]: # Check for division by zero\n",
    "        raise ZeroDivisionError(\"Cannot divide by zero.\")\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result /= num\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfy1M2fQi5_M",
    "outputId": "89e8184c-cc78-4f44-f8e4-9dc2ae3b3f30",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add([2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPM2zCgFi2Y-",
    "outputId": "5c345814-e7bd-4ec7-d865-9d6aac8646fe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply([2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1A65tOZMhnU5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_math_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"simple_math_agent\",\n",
    "    description=\"This agent performs basic arithmetic operations (addition, subtraction, multiplication, and division) on user-provided numbers, including ranges.\",\n",
    "    instruction=\"\"\"\n",
    "      I can perform addition, subtraction, multiplication, and division operations on numbers you provide.\n",
    "      Tell me the numbers you want to operate on.\n",
    "      For example, you can say 'add 3 5', 'multiply 2, 4 and 3', 'Subtract 10 from 20', 'Divide 10 by 2'.\n",
    "      You can also provide a range: 'Multiply the numbers between 1 and 10'.\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(temperature=0.2),\n",
    "    tools=[add, subtract, multiply, divide],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "E2mao_CshvB4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "async def caller_factory(root_agent, app_name='App12345', user_id='User12345', session_id=None):\n",
    "    \"\"\"create a pre-configured agent caller.\n",
    "    Args:\n",
    "        root_agent: The ADK agent to handle conversations\n",
    "        app_name: Application name (default: 'App12345')\n",
    "        user_id: User identifier (default: 'User12345')\n",
    "        session_id: Optional session ID. If None, generates a random one.\n",
    "    Returns:\n",
    "        A function that takes a query string and returns agent response events.\n",
    "    \"\"\"\n",
    "    session_service = InMemorySessionService()\n",
    "    if session_id is None:\n",
    "        suffix = random.randint(100000, 999999)\n",
    "        session_id = f'{app_name}-{user_id}-{suffix}'\n",
    "    \n",
    "    session = await session_service.create_session(\n",
    "        app_name=app_name, \n",
    "        user_id=user_id, \n",
    "        session_id=session_id\n",
    "    )\n",
    "    runner = Runner(agent=root_agent, app_name=app_name, session_service=session_service)\n",
    "    \n",
    "    def _call(query):\n",
    "        content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "        events = runner.run(user_id=session.user_id, session_id=session.id, new_message=content)\n",
    "        return list(events)  # Convert generator to list\n",
    "    \n",
    "    return _call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "nazjCHGikpKU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1219651/3527633880.py:2: RuntimeWarning: coroutine 'caller_factory' was never awaited\n",
      "  call = await caller_factory(root_agent=simple_math_agent)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.065 ms):\n",
      "Hello!  I can perform addition, subtraction, multiplication, and division operations on numbers you provide.  Tell me the numbers you want to operate on. For example, you can say 'add 3 5', 'multiply 2, 4 and 3', 'Subtract 10 from 20', 'Divide 10 by 2'. You can also provide a range: 'Multiply the numbers between 1 and 10'.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.18 ms\n"
     ]
    }
   ],
   "source": [
    "# Correct way - use await to get the actual callable function\n",
    "call = await caller_factory(root_agent=simple_math_agent)\n",
    "pprint_events(call('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1Trlwy8jxKc",
    "outputId": "5d3566fd-46ec-4c4d-94fb-ae436666d144",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: add, Args: {'numbers': [3, 9]}\n",
      "--- Function Responses:\n",
      "Function Name: add\n",
      "Function Results: [12]\n",
      ">>> Final Response (0.27 ms):\n",
      "12\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.291 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('what is three plus 9?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8ALwc-Tj0ks",
    "outputId": "db8fb5d7-534b-4d2a-ea93-ae6169838c2e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: multiply, Args: {'numbers': [12, 2]}\n",
      "--- Function Responses:\n",
      "Function Name: multiply\n",
      "Function Results: [24]\n",
      ">>> Final Response (0.251 ms):\n",
      "24\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.272 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('multiply that by 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvkmTH73j-oA",
    "outputId": "ec8be16f-6d46-4e75-e663-bb0d18bfdcaa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1219651/3373569892.py:1: RuntimeWarning: coroutine 'caller_factory' was never awaited\n",
      "  call = await caller_factory(root_agent=simple_math_agent)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.053 ms):\n",
      "Okay, you have three apples. What would you like to do with them?  I can add, subtract, multiply, or divide the number of apples.  Tell me your next instruction.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.163 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=simple_math_agent)\n",
    "pprint_events(call('Here is my math problem that is about apple counting. Let us start saying that I have three apple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWRB6xfKkBpo",
    "outputId": "0bea7066-554f-492c-e638-42daf546e0c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.051 ms):\n",
      "Okay, Alice gave you 2 more apples.  So you started with 3 apples and received 2 more.  That means you now have 3 + 2 = 5 apples.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.168 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('Alice gave anoter 2 apples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tChA_Yaxk1IM",
    "outputId": "9a66a2e0-02a4-44c4-f753-5ab9c64d18cb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.067 ms):\n",
      "You have 5 apples.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.178 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('how many apples do I have?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2iaQ03yk760",
    "outputId": "9c019228-4927-4220-d2af-3605122e1fe7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.055 ms):\n",
      "You had 5 apples, and Bob gave you 3 more.  Therefore, you now have 5 + 3 = 8 apples.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.17 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('Bob gave me 3 apples. how many apples do I have?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVZAUuTRlApx",
    "outputId": "822f61bf-0dfb-44d6-c91d-ad87c39bd944",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.082 ms):\n",
      "Each time, you receive a total of 2 + 3 = 5 apples from Alice and Bob. This happens three more times.  So you'll receive an additional 5 * 3 = 15 apples.\n",
      "\n",
      "You started with 8 apples, and you'll receive 15 more, giving you a total of 8 + 15 = 23 apples.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.216 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('Alice and Bob do this to me for three more times. how many apples do I have?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Xa9hTJhVEIv",
    "outputId": "36dd545f-e96b-46c7-bb5e-b523eb70d1fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.069 ms):\n",
      "Great! Is there anything else I can help you calculate?\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.212 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('yes your logic is correct'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTdOCFO4i6qF"
   },
   "source": [
    "# Agent As Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62lUo7Eui9iE"
   },
   "source": [
    "**AgentTool:** You can embed the power of one agent within another by using AgentTool. This allows you to treat an entire agent as a tool within a parent agent. AgentTools are executed in an isolated environment, promoting safety and modularity. Combined with input/output schemas, this enables the creation of sophisticated interactions\n",
    "\n",
    "\n",
    "Function Tool vs Agent Tool:\n",
    " If the execution flow goes from Agent to Tool and it always come back to theinitiation agent vs if the execution flow goes from Agent to **another** agent, the latter agent can decide where the flow goes next.\n",
    "\n",
    "Concepts:\n",
    "- AgentTool -- If you want another agent to handle a task and always come back to the caller, make this `Agent` a `Tool` by `AgentTool`\n",
    "\n",
    "Use case:\n",
    "- Advanced math agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "U2tB6OuUi8UH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_math_advanced_instruction = '''\n",
    "I am an advanced math agent. I handle user query in the below steps:\n",
    "\n",
    "1. I shall analyse the chat log to understand current question and make a math formula for it.\n",
    "2. Break down a complex compuation based on arithmetic priority and hand over to simple_math_agent for the calculation.\n",
    "3. Note that simple_math_agent can only understand numbers, so I need to convert natural language expression of numbers into digits.\n",
    "\n",
    "<example>\n",
    "<input> alice gives us 3 apples, bob gives us 5 apples. They do this seven times. Then we eat four apples. How many apples do we have now? </input>\n",
    "<think> what is (3+5) * 7 -4 </think>\n",
    "<think>I need to first calculate (3+5) as the highest priority operation.</think>\n",
    "<call_tool> pass (3+5) to simple_math_agent </call_tool>\n",
    "<tool_response>8</tool_response>\n",
    "<think> The question now becomes 8 * 7 - 4, and next highest operation is 8 * 7</think>\n",
    "<call_tool> pass 8 * 7 to simple_math_agent </call_tool>\n",
    "<tool_response>56</tool_response>\n",
    "<think> The question now becomes 56 - 4, and next highest operation is 56 - 4</think>\n",
    "<call_tool> pass 56 - 4 to simple_math_agent </call_tool>\n",
    "<tool_response>52</tool_response>\n",
    "<think>There is a single number, so it is the final answer.</think>\n",
    "<output>The result of \"(3+5) * 7 - 4\" is 52</output>\n",
    "</example>\n",
    "'''\n",
    "\n",
    "agent_math_advanced = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"agent_math_advanced\",\n",
    "    description=\"The advanced math agent can break down a complex computation into multiple simple operations and use math_agent to solve them.\",\n",
    "    instruction=agent_math_advanced_instruction,\n",
    "    tools=[AgentTool(agent=simple_math_agent)],\n",
    "    generate_content_config=types.GenerateContentConfig(temperature=0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_LJ6BDn-meCU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "call = await caller_factory(root_agent=agent_math_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmBOvh0xn4PX",
    "outputId": "8bda2a6e-29e7-4ced-900a-da321982e0e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.08 ms):\n",
      "I am agent_math_advanced.  The advanced math agent can break down a complex computation into multiple simple operations and use math_agent to solve them.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.258 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('who are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEm29jQomhUf",
    "outputId": "36cc290f-df2c-44e0-b3a2-353f143e69d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: simple_math_agent, Args: {'request': '3+2'}\n",
      "--- Function Responses:\n",
      "Function Name: simple_math_agent\n",
      "Function Results: [\"The result is 5.\\n\"]\n",
      "+++ Function Calls:\n",
      "Function Name: simple_math_agent, Args: {'request': '1 + 5 * 7'}\n",
      "--- Function Responses:\n",
      "Function Name: simple_math_agent\n",
      "Function Results: [\"Following the order of operations (PEMDAS/BODMAS), multiplication is performed before addition.\\n\\n1. **Multiplication:** 5 * 7 = 35\\n2. **Addition:** 1 + 35 = 36\\n\\nTherefore, the answer is $\\\\boxed{36}$\\n\"]\n",
      ">>> Final Response (0.342 ms):\n",
      "The result of \"1 + (three+2) times 7\" is 36\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.363 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('what is 1 + (three+2) times 7 '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "NeUqlKtfmocA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "call = await caller_factory(root_agent=agent_math_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0GD-_YLpoeX",
    "outputId": "bd283415-1d95-4098-c3f8-0c1ac97bd6ec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: simple_math_agent, Args: {'request': '1+2'}\n",
      "--- Function Responses:\n",
      "Function Name: simple_math_agent\n",
      "Function Results: [\"3\\n\"]\n",
      "+++ Function Calls:\n",
      "Function Name: simple_math_agent, Args: {'request': '3*2'}\n",
      "--- Function Responses:\n",
      "Function Name: simple_math_agent\n",
      "Function Results: [\"The answer is 6.\\n\"]\n",
      ">>> Final Response (0.344 ms):\n",
      "The result of \"((1+2)*2)\" is 6.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.364 ms\n"
     ]
    }
   ],
   "source": [
    "pprint_events(call('add from 1 to 2. then multiply that by 2.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQmUaZULu1Ox",
    "outputId": "3c858361-8a8f-482b-fa7f-308eeb630134",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: simple_math_agent, Args: {'request': '10 / 5 + 3 * 5'}\n",
      "--- Function Responses:\n",
      "Function Name: simple_math_agent\n",
      "Function Results: [\"Following the order of operations (PEMDAS/BODMAS), we calculate:\\n\\n1. **Division:** 10 / 5 = 2\\n2. **Multiplication:** 3 * 5 = 15\\n3. **Addition:** 2 + 15 = 17\\n\\nTherefore, the answer is $\\\\boxed{17}$\\n\"]\n",
      ">>> Final Response (0.346 ms):\n",
      "The result is 17.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.384 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=agent_math_advanced)\n",
    "pprint_events(call('how much is 10 / 5 + three times 5?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWTUQ6cMmzJz"
   },
   "source": [
    "**NOTE**: This part is very nice, it shows how two agents interact to clarify the input type should be integers and input again.\n",
    "\n",
    "```\n",
    "+++ inside the function call...\n",
    "function, [args]:  simple_math_agent, {'request': '2.0 + 15'}\n",
    "--- inside the function call response...\n",
    "Function Name: simple_math_agent\n",
    "Function Results [\"I can only work with integers. Could you provide the numbers as integers?\\n\"]\n",
    "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n",
    "+++ inside the function call...\n",
    "function, [args]:  simple_math_agent, {'request': '2 + 15'}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnI-dGgTw0Up"
   },
   "source": [
    "# Input/Output Format Control\n",
    "\n",
    "**Input Schema / Output Schema:** Ensure data consistency and validity by defining Pydantic schemas for your agent's input and output. The agent can then verify the input against the schema and guarantee that the generated output conforms to the specified structure using constrained decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5sc1phw1vml",
    "outputId": "30f3803b-2349-4bb4-b3d4-2fe9486c9d92",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'original_query': {'description': 'The original text from user.',\n",
       "   'title': 'Original Query',\n",
       "   'type': 'string'},\n",
       "  'corrected_text': {'description': 'The corrected text.',\n",
       "   'title': 'Corrected Text',\n",
       "   'type': 'string'},\n",
       "  'errors': {'description': 'An array of descriptions of each error.',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Errors',\n",
       "   'type': 'array'},\n",
       "  'explanations': {'description': 'An array of explanations for each correction.',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Explanations',\n",
       "   'type': 'array'}},\n",
       " 'required': ['original_query', 'corrected_text', 'errors', 'explanations'],\n",
       " 'title': 'OutputSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from google.genai import types\n",
    "\n",
    "json_response_config = types.GenerateContentConfig(\n",
    "  response_mime_type=\"application/json\",\n",
    ")\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    original_query: str = Field(description=\"The original text from user.\")\n",
    "    corrected_text: str = Field(description=\"The corrected text.\")\n",
    "    errors: List[str] = Field(description=\"An array of descriptions of each error.\")\n",
    "    explanations: List[str] = Field(description=\"An array of explanations for each correction.\")\n",
    "\n",
    "json_schema = OutputSchema.model_json_schema()\n",
    "json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "oxcvrIybw39T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. The {json_schema} in instruction is the key for model to follow the schema.\n",
    "# 2. The output_schema=OutputSchema provides a validation step after model output.\n",
    "\n",
    "agent_grammar = Agent(\n",
    "    model=MODEL,\n",
    "    name='agent_grammar',\n",
    "    description=\"This agent corrects grammar mistakes in text provided by children, explains the errors in simple terms, and returns both the corrected text and the explanations.\",\n",
    "    instruction=f\"\"\"\n",
    "        You are a friendly grammar helper for kids.  Analyze the following text,\n",
    "        correct any grammar mistakes, and explain the errors in a way that a\n",
    "        child can easily understand.  Don't just list the errors; explain them\n",
    "        in a paragraph using simple but concise language.\n",
    "\n",
    "        Output in a JSON object with the below schema:\n",
    "        {json_schema}\n",
    "    \"\"\",\n",
    "    output_schema=OutputSchema,\n",
    "    generate_content_config=json_response_config,\n",
    "    disallow_transfer_to_parent = True,\n",
    "    disallow_transfer_to_peers=True\n",
    "    \n",
    "    # allow_transfer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview import reasoning_engines\n",
    "\n",
    "app = reasoning_engines.AdkApp(\n",
    "    agent=agent_grammar,\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {'parts': [{'text': '{\"original_query\": \"whats the weather in new york\", \"corrected_text\": \"What is the weather in New York?\", \"errors\": [\"The sentence starts with a lowercase letter and uses informal contractions.\", \"New York should be capitalized.\"], \"explanations\": [\"Sentences always start with a capital letter.  We used \\\\\"What is\\\\\" instead of \\\\\"whats\\\\\" to sound more proper. \", \"New York is a proper noun, so it needs a capital letter for both words.\"]}'}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 101, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 101}], 'prompt_token_count': 368, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 368}], 'total_token_count': 469, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-705d7765-12a1-463d-82be-42bff5a9efac', 'author': 'agent_grammar', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}}, 'id': 'gDRJJKUz', 'timestamp': 1750686624.97123}\n"
     ]
    }
   ],
   "source": [
    "for event in app.stream_query(\n",
    "    user_id=\"u_123\",\n",
    "    # session_id=session.id,\n",
    "    message=\"whats the weather in new york\",\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOO130ZYd5he"
   },
   "source": [
    "Conversation Flow:\n",
    "\n",
    "The session contains multiple interactions where the user asks questions with intentional misspellings, and the agent corrects them. Here are the main interactions:\n",
    "\n",
    "Response Format: Each agent response is in JSON format containing:\n",
    "\n",
    "- original_query: The user's input\n",
    "- corrected_text: The corrected version\n",
    "- errors: List of error types found\n",
    "- explanations: Detailed explanations of the corrections\n",
    "- Technical Details: Each interaction has a unique invocation_id\n",
    "- Events are timestamped\n",
    "- The session maintains state and tracks all events\n",
    "\n",
    "\n",
    "To summarize, this agent:\n",
    "\n",
    "1. Accepts user input\n",
    "2. Identifies grammatical and spelling errors\n",
    "3. Provides corrected versions\n",
    "4. Explains the corrections\n",
    "5. Maintains a conversation history\n",
    "6. The agent is particularly focused on:\n",
    "7. Spelling corrections (e.g., \"ho\" → \"how\", \"whut\" → \"what\")\n",
    "8. Sentence structure (e.g., adding missing \"be\")\n",
    "9. Providing educational explanations for each correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting Agent on Agent engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-2.0-flash-001\"\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.OFF,\n",
    "    ),\n",
    "]\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    safety_settings=safety_settings,\n",
    "    temperature=0.28,\n",
    "    max_output_tokens=1000,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "import vertexai\n",
    "from vertexai import agent_engines\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "STAGING_BUCKET = GCS_BUCKET_URI\n",
    "\n",
    "PROJECT_IDS = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_IDS[0]  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\" #@param {type:\"string\"}\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {'parts': [{'text': \"Please specify which Swedish currency you're asking about. Sweden uses the Swedish Krona (SEK). Once you confirm that's what you're looking for, I can provide the current exchange rate.\\n\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 42, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 42}], 'prompt_token_count': 28, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 28}], 'total_token_count': 70, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-3c81f408-5e87-40d5-a110-7c142baacf8e', 'author': 'currency_exchange_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}}, 'id': 'AolTACAo', 'timestamp': 1750686678.472449}\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,                                      # Required.\n",
    "    name='currency_exchange_agent',                   # Required.\n",
    "    generate_content_config=generate_content_config,  # Optional.\n",
    ")\n",
    "app = AdkApp(agent=agent)\n",
    "for event in app.stream_query(\n",
    "    user_id=\"ysian\",  # Required\n",
    "    message=\"What is the exchange rate from US dollars to Swedish currency?\",\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Tracability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {'parts': [{'text': \"I can't provide you with a specific exchange rate for USD to SEK on April 3, 2025. Exchange rates fluctuate constantly based on market conditions. You'll need to check a reliable source closer to that date to get an accurate rate.\\n\\nHere's where you can find exchange rates:\\n\\n*   **Financial websites:** Reputable financial websites (like Google Finance, Yahoo Finance, Bloomberg, etc.) will provide current and historical exchange rates.\\n*   **Currency converters:** Many online currency converters are available, but make sure they use a reliable data source.\\n*   **Banks and financial institutions:** Your bank or a currency exchange service will give you the current exchange rate they are offering.\"}], 'role': 'model'}, 'usage_metadata': {'candidates_token_count': 147, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 147}], 'prompt_token_count': 40, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 40}], 'total_token_count': 187, 'traffic_type': <TrafficType.ON_DEMAND: 'ON_DEMAND'>}, 'invocation_id': 'e-2969a029-bb4b-4cd4-8199-c44213bf7ccc', 'author': 'currency_exchange_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}}, 'id': 'OxbjvCO3', 'timestamp': 1750686687.655381}\n"
     ]
    }
   ],
   "source": [
    "app = AdkApp(\n",
    "    agent=agent,\n",
    "    enable_tracing=True, # <- new\n",
    ")\n",
    "\n",
    "for event in app.stream_query(\n",
    "    user_id=\"saurabh\",\n",
    "    message=\"What is the exchange rate from US dollars to Swedish currency on 2025-04-03?\",\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Engine hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following requirements: {'pydantic': '2.11.7', 'google-cloud-aiplatform': '1.98.0', 'cloudpickle': '3.0.0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Identified the following requirements: {'pydantic': '2.11.7', 'google-cloud-aiplatform': '1.98.0', 'cloudpickle': '3.0.0'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following requirements are missing: {'pydantic', 'cloudpickle'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:vertexai.agent_engines:The following requirements are missing: {'pydantic', 'cloudpickle'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following requirements are appended: {'cloudpickle==3.0.0', 'pydantic==2.11.7'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:The following requirements are appended: {'cloudpickle==3.0.0', 'pydantic==2.11.7'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final list of requirements: ['google-cloud-aiplatform[agent_engines,adk]', 'cloudpickle==3.0.0', 'pydantic==2.11.7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:The final list of requirements: ['google-cloud-aiplatform[agent_engines,adk]', 'cloudpickle==3.0.0', 'pydantic==2.11.7']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket my-project-0004-346516-sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Using bucket my-project-0004-346516-sm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to gs://my-project-0004-346516-sm/agent_engine/agent_engine.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Wrote to gs://my-project-0004-346516-sm/agent_engine/agent_engine.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to gs://my-project-0004-346516-sm/agent_engine/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Writing to gs://my-project-0004-346516-sm/agent_engine/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating in-memory tarfile of extra_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Creating in-memory tarfile of extra_packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to gs://my-project-0004-346516-sm/agent_engine/dependencies.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Writing to gs://my-project-0004-346516-sm/agent_engine/dependencies.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AgentEngine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Creating AgentEngine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create AgentEngine backing LRO: projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240/operations/6223853566948278272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:Create AgentEngine backing LRO: projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240/operations/6223853566948278272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View progress and logs at https://console.cloud.google.com/logs/query?project=my-project-0004-346516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:View progress and logs at https://console.cloud.google.com/logs/query?project=my-project-0004-346516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentEngine created. Resource name: projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:AgentEngine created. Resource name: projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this AgentEngine in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:To use this AgentEngine in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_engine = vertexai.agent_engines.get('projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.agent_engines:agent_engine = vertexai.agent_engines.get('projects/255766800726/locations/us-central1/reasoningEngines/9072334323570442240')\n"
     ]
    }
   ],
   "source": [
    "remote_app = agent_engines.create(\n",
    "    app,\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"],\n",
    "    display_name=\"exchange_rate_agent\",\n",
    "    description=\"Agent Engine that uses ADK\",        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'api_mode': '',\n",
      "  'description': 'Get a session for the given user.',\n",
      "  'name': 'get_session',\n",
      "  'parameters': {'properties': {'session_id': {'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id', 'session_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': '',\n",
      "  'description': 'List sessions for the given user.',\n",
      "  'name': 'list_sessions',\n",
      "  'parameters': {'properties': {'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': '',\n",
      "  'description': 'Creates a new session.',\n",
      "  'name': 'create_session',\n",
      "  'parameters': {'properties': {'session_id': {'nullable': True,\n",
      "                                               'type': 'string'},\n",
      "                                'state': {'nullable': True, 'type': 'object'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': '',\n",
      "  'description': 'Deletes a session for the given user.',\n",
      "  'name': 'delete_session',\n",
      "  'parameters': {'properties': {'session_id': {'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id', 'session_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'async',\n",
      "  'description': 'Get a session for the given user.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            session_id (str):\\n'\n",
      "                 '                Required. The ID of the session.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                session service.\\n'\n",
      "                 '\\n'\n",
      "                 '        Returns:\\n'\n",
      "                 '            Session: The session instance (if any). It '\n",
      "                 'returns None if the\\n'\n",
      "                 '            session is not found.\\n'\n",
      "                 '\\n'\n",
      "                 '        Raises:\\n'\n",
      "                 '            RuntimeError: If the session is not found.\\n'\n",
      "                 '        ',\n",
      "  'name': 'async_get_session',\n",
      "  'parameters': {'properties': {'session_id': {'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id', 'session_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'async',\n",
      "  'description': 'List sessions for the given user.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                session service.\\n'\n",
      "                 '\\n'\n",
      "                 '        Returns:\\n'\n",
      "                 '            ListSessionsResponse: The list of sessions.\\n'\n",
      "                 '        ',\n",
      "  'name': 'async_list_sessions',\n",
      "  'parameters': {'properties': {'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'async',\n",
      "  'description': 'Creates a new session.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            session_id (str):\\n'\n",
      "                 '                Optional. The ID of the session. If not '\n",
      "                 'provided, an ID\\n'\n",
      "                 '                will be be generated for the session.\\n'\n",
      "                 '            state (dict[str, Any]):\\n'\n",
      "                 '                Optional. The initial state of the session.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                session service.\\n'\n",
      "                 '\\n'\n",
      "                 '        Returns:\\n'\n",
      "                 '            Session: The newly created session instance.\\n'\n",
      "                 '        ',\n",
      "  'name': 'async_create_session',\n",
      "  'parameters': {'properties': {'session_id': {'nullable': True,\n",
      "                                               'type': 'string'},\n",
      "                                'state': {'nullable': True, 'type': 'object'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'async',\n",
      "  'description': 'Deletes a session for the given user.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            session_id (str):\\n'\n",
      "                 '                Required. The ID of the session.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                session service.\\n'\n",
      "                 '        ',\n",
      "  'name': 'async_delete_session',\n",
      "  'parameters': {'properties': {'session_id': {'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['user_id', 'session_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'stream',\n",
      "  'description': 'Streams responses from the ADK application in response to a '\n",
      "                 'message.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            message (Union[str, Dict[str, Any]]):\\n'\n",
      "                 '                Required. The message to stream responses '\n",
      "                 'for.\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            session_id (str):\\n'\n",
      "                 '                Optional. The ID of the session. If not '\n",
      "                 'provided, a new\\n'\n",
      "                 '                session will be created for the user.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                runner.\\n'\n",
      "                 '\\n'\n",
      "                 '        Yields:\\n'\n",
      "                 '            The output of querying the ADK application.\\n'\n",
      "                 '        ',\n",
      "  'name': 'stream_query',\n",
      "  'parameters': {'properties': {'message': {'anyOf': [{'type': 'string'},\n",
      "                                                      {'additionalProperties': True,\n",
      "                                                       'type': 'object'}]},\n",
      "                                'session_id': {'nullable': True,\n",
      "                                               'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['message', 'user_id'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'stream',\n",
      "  'description': None,\n",
      "  'name': 'streaming_agent_run_with_events',\n",
      "  'parameters': {'properties': {'request_json': {'type': 'string'}},\n",
      "                 'required': ['request_json'],\n",
      "                 'type': 'object'}},\n",
      " {'api_mode': 'async_stream',\n",
      "  'description': 'Streams responses asynchronously from the ADK application.\\n'\n",
      "                 '\\n'\n",
      "                 '        Args:\\n'\n",
      "                 '            message (str):\\n'\n",
      "                 '                Required. The message to stream responses '\n",
      "                 'for.\\n'\n",
      "                 '            user_id (str):\\n'\n",
      "                 '                Required. The ID of the user.\\n'\n",
      "                 '            session_id (str):\\n'\n",
      "                 '                Optional. The ID of the session. If not '\n",
      "                 'provided, a new\\n'\n",
      "                 '                session will be created for the user.\\n'\n",
      "                 '            **kwargs (dict[str, Any]):\\n'\n",
      "                 '                Optional. Additional keyword arguments to '\n",
      "                 'pass to the\\n'\n",
      "                 '                runner.\\n'\n",
      "                 '\\n'\n",
      "                 '        Yields:\\n'\n",
      "                 '            Event dictionaries asynchronously.\\n'\n",
      "                 '        ',\n",
      "  'name': 'async_stream_query',\n",
      "  'parameters': {'properties': {'message': {'anyOf': [{'type': 'string'},\n",
      "                                                      {'additionalProperties': True,\n",
      "                                                       'type': 'object'}]},\n",
      "                                'session_id': {'nullable': True,\n",
      "                                               'type': 'string'},\n",
      "                                'user_id': {'type': 'string'}},\n",
      "                 'required': ['message', 'user_id'],\n",
      "                 'type': 'object'}}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(remote_app.operation_schemas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_agent = Agent(\n",
    "    name='basic_agent',\n",
    "    description='A helpful assistant for user.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"Answer user's question with your best knowledge.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner = create_runner(basic_agent)\n",
    "session =  run_session(content_text('Hello!'), runner=runner)\n",
    "session =  run_session(content_text('Tell me a joke under 30 words?'), runner=runner, session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object run_session at 0x7faad7d8f140>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.069 ms):\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.201 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=basic_agent)\n",
    "pprint_events(call('Tell me a joke under 30 words'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_agent_1 = Agent(\n",
    "    name='sub_agent_1',\n",
    "    description='No.1 sub agent.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"JUST SAY 1.\",\n",
    ")\n",
    "\n",
    "sub_agent_2 = Agent(\n",
    "    name='sub_agent_2',\n",
    "    description='No.2 sub agent.',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction=\"JUST SAY 2.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequential_agent = SequentialAgent(\n",
    "    name='sequential_agent',\n",
    "    sub_agents=[sub_agent_1, sub_agent_2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.059 ms):\n",
      "1.\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.204 ms):\n",
      "2.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.229 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=sequential_agent)\n",
    "pprint_events(call('hi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: child_1_agent\\nContent Text: 1.\\n\\n...\\n\\nAuthor: child_2_agent\\nContent Text: 2.\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect output:\n",
    "\"\"\"\n",
    "Author: child_1_agent\n",
    "Content Text: 1.\n",
    "\n",
    "...\n",
    "\n",
    "Author: child_2_agent\n",
    "Content Text: 2.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "\n",
    "APP_NAME = 'test_app'\n",
    "USER_ID = 'test_user'\n",
    "\n",
    "def create_runner(agent: BaseAgent):\n",
    "  return InMemoryRunner(agent, app_name=APP_NAME)\n",
    "\n",
    "def _content_to_text(content: types.Content | None) -> str:\n",
    "  if not content or not content.parts:\n",
    "    return ''\n",
    "  return ''.join([p.text or '' for p in content.parts])\n",
    "\n",
    "def print_event(event: Event):\n",
    "  print(f'Author: {event.author}')\n",
    "  print(f'Content Text: {_content_to_text(event.content)}')\n",
    "  print(f'Event: {event.model_dump(exclude_none=True, exclude_defaults=True)}')\n",
    "\n",
    "async def run_session(new_message: types.Content, *, runner: Runner, session: Optional[Session] = None, state: Optional[dict[str, Any]] = None) -> Session:\n",
    "  if session is None:\n",
    "    session = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID, state=state)\n",
    "\n",
    "  print(f'User: {_content_to_text(new_message)}')\n",
    "  print('----------------------------------')\n",
    "  async for e in runner.run_async(user_id=USER_ID, session_id=session.id, new_message=new_message):\n",
    "    print_event(e)\n",
    "  print('----------------------------------')\n",
    "\n",
    "  session = runner.session_service.get_session(app_name=session.app_name, user_id=session.user_id, session_id=session.id)\n",
    "  return session\n",
    "\n",
    "def content_text(msg: str) -> types.Content:\n",
    "  return types.UserContent(parts=[types.Part(text=msg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def roll_die(sides: int) -> int:\n",
    "  \"\"\"Roll a die and return the rolled result.\n",
    "\n",
    "  Args:\n",
    "    sides: The integer number of sides the die has.\n",
    "\n",
    "  Returns:\n",
    "    An integer of the result of rolling the die.\n",
    "  \"\"\"\n",
    "  return random.randint(1, sides)\n",
    "\n",
    "\n",
    "single_agent_1 = Agent(\n",
    "    name='async_agent_1',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 8 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=False,\n",
    "    disallow_transfer_to_peers=False,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "single_agent_2 = Agent(\n",
    "    name='async_agent_2',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 10 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=False,\n",
    "    disallow_transfer_to_peers=False,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "single_agent_3 = Agent(\n",
    "    name='async_agent_3',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    instruction='Just roll a dice of 15 sides when being asked to roll a die.',\n",
    "    disallow_transfer_to_parent=False,\n",
    "    disallow_transfer_to_peers=False,\n",
    "    tools=[roll_die],\n",
    ")\n",
    "parallel_agent = ParallelAgent(\n",
    "    name='parallel_agent',\n",
    "    sub_agents=[\n",
    "        single_agent_1,\n",
    "        single_agent_2,\n",
    "        single_agent_3,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad4410e80> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad7ddb400> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad7de4e00> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad445cc40> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad442f840> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad440bcc0> was created in a different Context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.066 ms):\n",
      "Hello! How can I help you today?\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.182 ms):\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.226 ms):\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.25 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=parallel_agent)\n",
    "pprint_events(call('Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad442a040> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad443ee40> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad7dd9a80> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad445c2c0> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad445c600> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad44a9500> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad4449d40> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad7dd9600> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad7dd9900> was created in a different Context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Function Calls:\n",
      "Function Name: roll_die, Args: {'sides': 100}\n",
      "--- Function Responses:\n",
      "Function Name: roll_die\n",
      "Function Results: [55]\n",
      "+++ Function Calls:\n",
      "Function Name: roll_die, Args: {'sides': 100}\n",
      "--- Function Responses:\n",
      "Function Name: roll_die\n",
      "Function Results: [6]\n",
      "+++ Function Calls:\n",
      "Function Name: roll_die, Args: {'sides': 100}\n",
      "--- Function Responses:\n",
      "Function Name: roll_die\n",
      "Function Results: [1]\n",
      ">>> Final Response (0.514 ms):\n",
      "I rolled a 100-sided die and got 55.\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.568 ms):\n",
      "I rolled a 100-sided die and got 6.\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.638 ms):\n",
      "I rolled a 100-sided die and got a 1.\n",
      "\n",
      "------------------------------\n",
      "Total elapsed time: 0.665 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=parallel_agent)\n",
    "pprint_events(call('Roll a dice of 100 sides and tell me what you got'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'original_query': {'description': 'The original text from user.', 'title': 'Original Query', 'type': 'string'}, 'corrected_text': {'description': 'The corrected text.', 'title': 'Corrected Text', 'type': 'string'}, 'errors': {'description': 'An array of descriptions of each error.', 'items': {'type': 'string'}, 'title': 'Errors', 'type': 'array'}, 'explanations': {'description': 'An array of explanations for each correction.', 'items': {'type': 'string'}, 'title': 'Explanations', 'type': 'array'}}, 'required': ['original_query', 'corrected_text', 'errors', 'explanations'], 'title': 'OutputSchema', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "from google.adk.agents import Agent\n",
    "from google.genai import types\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.agents.loop_agent import LoopAgent\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from google.genai import types\n",
    "\n",
    "json_response_config = types.GenerateContentConfig(\n",
    "  response_mime_type=\"application/json\",\n",
    ")\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    original_query: str = Field(description=\"The original text from user.\")\n",
    "    corrected_text: str = Field(description=\"The corrected text.\")\n",
    "    errors: List[str] = Field(description=\"An array of descriptions of each error.\")\n",
    "    explanations: List[str] = Field(description=\"An array of explanations for each correction.\")\n",
    "\n",
    "json_schema = OutputSchema.model_json_schema()\n",
    "print(json_schema)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "\n",
    "agent_grammar = Agent(\n",
    "    model=MODEL,\n",
    "    name='agent_grammar',\n",
    "    description=\"This agent corrects grammar mistakes in text provided by children, explains the errors in simple terms, and returns both the corrected text and the explanations.\",\n",
    "    instruction=f\"\"\"\n",
    "        You are a friendly grammar helper for kids.  Analyze the following text,\n",
    "        correct any grammar mistakes, and explain the errors in a way that a\n",
    "        child can easily understand.  Don't just list the errors; explain them\n",
    "        in a paragraph using simple but concise language.\n",
    "\n",
    "        Output in a JSON object with the below schema:\n",
    "        {json_schema}\n",
    "    \"\"\",\n",
    "    output_schema=OutputSchema,\n",
    "    generate_content_config=json_response_config,\n",
    "    # allow_transfer=False,\n",
    ")\n",
    "\n",
    "def add(numbers: list[int]) -> int:\n",
    "  \"\"\"Calculates the sum of a list of integers.\n",
    "\n",
    "    This function takes a list of integers as input and returns the sum of all\n",
    "    the elements in the list.  It uses the built-in `sum()` function for\n",
    "    efficiency.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be added.\n",
    "\n",
    "    Returns:\n",
    "        The sum of the integers in the input list.  Returns 0 if the input\n",
    "        list is empty.\n",
    "\n",
    "    Examples:\n",
    "        add([1, 2, 3]) == 6\n",
    "        add([-1, 0, 1]) == 0\n",
    "        add([]) == 0\n",
    "    \"\"\"\n",
    "  return sum(numbers)\n",
    "\n",
    "def subtract(numbers: list[int]) -> int:\n",
    "    \"\"\"Subtracts numbers in a list sequentially from left to right.\n",
    "\n",
    "    This function performs subtraction on a list of integers, applying the\n",
    "    subtraction operation from left to right.  For example, given the list\n",
    "    [10, 2, 5], the function will calculate 10 - 2 - 5.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be subtracted.\n",
    "\n",
    "    Returns:\n",
    "        The result of the sequential subtraction as an integer. Returns 0 if the input list is empty.\n",
    "\n",
    "    Examples:\n",
    "        subtract([10, 2, 5]) == 3  # (10 - 2) - 5 = 8 - 5 = 3\n",
    "        subtract([10, 2]) == 8      # 10 - 2 = 8\n",
    "        subtract([]) == 0\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        return 0  # Handle empty list\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result -= num\n",
    "    return result\n",
    "\n",
    "def multiply(numbers: list[int]) -> int:\n",
    "  \"\"\"Calculates the product of a list of integers.\n",
    "\n",
    "    This function takes a list of integers as input and returns the product of all\n",
    "    the elements in the list. It iterates through the list, multiplying each\n",
    "    number with the accumulated product.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be multiplied.\n",
    "\n",
    "    Returns:\n",
    "        The product of the integers in the input list. Returns 1 if the input\n",
    "        list is empty.\n",
    "\n",
    "    Examples:\n",
    "        multiply([2, 3, 4]) == 24  # 2 * 3 * 4 = 24\n",
    "        multiply([1, -2, 5]) == -10 # 1 * -2 * 5 = -10\n",
    "        multiply([]) == 1\n",
    "    \"\"\"\n",
    "  product = 1\n",
    "  for num in numbers:\n",
    "    product *= num\n",
    "  return product\n",
    "\n",
    "def divide(numbers: list[int]) -> float:  # Use float for division\n",
    "    \"\"\"Divides numbers in a list sequentially from left to right.\n",
    "\n",
    "    This function performs division on a list of integers, applying the division\n",
    "    operation from left to right.  For example, given the list [10, 2, 5], the\n",
    "    function will calculate 10 / 2 / 5.\n",
    "\n",
    "    Args:\n",
    "        numbers: A list of integers to be divided.\n",
    "\n",
    "    Returns:\n",
    "        The result of the sequential division as a float.\n",
    "\n",
    "    Raises:\n",
    "        ZeroDivisionError: If any number in the list *after* the first element\n",
    "                           is zero, a ZeroDivisionError is raised.  Division by\n",
    "                           zero is not permitted.\n",
    "\n",
    "    Returns:\n",
    "        float: The result of the division. Returns 0.0 if the input list is empty.\n",
    "\n",
    "    Examples:\n",
    "        divide([10, 2, 5]) == 1.0  # (10 / 2) / 5 = 5 / 5 = 1.0\n",
    "        divide([10, 2]) == 5.0      # 10 / 2 = 5.0\n",
    "        divide([10, 0, 5])  # Raises ZeroDivisionError\n",
    "        divide([]) == 0.0\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        return 0.0 # Handle empty list\n",
    "    if 0 in numbers[1:]: # Check for division by zero\n",
    "        raise ZeroDivisionError(\"Cannot divide by zero.\")\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result /= num\n",
    "    return result\n",
    "\n",
    "simple_math_agent = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"simple_math_agent\",\n",
    "    description=\"This agent performs basic arithmetic operations (addition, subtraction, multiplication, and division) on user-provided numbers, including ranges.\",\n",
    "    instruction=\"\"\"\n",
    "      I can perform addition, subtraction, multiplication, and division operations on numbers you provide.\n",
    "      Tell me the numbers you want to operate on.\n",
    "      For example, you can say 'add 3 5', 'multiply 2, 4 and 3', 'Subtract 10 from 20', 'Divide 10 by 2'.\n",
    "      You can also provide a range: 'Multiply the numbers between 1 and 10'.\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(temperature=0.2),\n",
    "    tools=[add, subtract, multiply, divide],\n",
    ")\n",
    "\n",
    "agent_math_advanced_instruction = '''\n",
    "I am an advanced math agent. I handle user query in the below steps:\n",
    "\n",
    "1. I shall analyse the chat log to understand current question and make a math formula for it.\n",
    "2. Break down a complex compuation based on arithmetic priority and hand over to simple_math_agent for the calculation.\n",
    "3. Note that simple_math_agent can only understand numbers, so I need to convert natural language expression of numbers into digits.\n",
    "\n",
    "<example>\n",
    "<input> alice gives us 3 apples, bob gives us 5 apples. They do this seven times. Then we eat four apples. How many apples do we have now? </input>\n",
    "<think> what is (3+5) * 7 -4 </think>\n",
    "<think>I need to first calculate (3+5) as the highest priority operation.</think>\n",
    "<call_tool> pass (3+5) to simple_math_agent </call_tool>\n",
    "<tool_response>8</tool_response>\n",
    "<think> The question now becomes 8 * 7 - 4, and next highest operation is 8 * 7</think>\n",
    "<call_tool> pass 8 * 7 to simple_math_agent </call_tool>\n",
    "<tool_response>56</tool_response>\n",
    "<think> The question now becomes 56 - 4, and next highest operation is 56 - 4</think>\n",
    "<call_tool> pass 56 - 4 to simple_math_agent </call_tool>\n",
    "<tool_response>52</tool_response>\n",
    "<think>There is a single number, so it is the final answer.</think>\n",
    "<output>The result of \"(3+5) * 7 - 4\" is 52</output>\n",
    "</example>\n",
    "'''\n",
    "\n",
    "agent_math_advanced = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"agent_math_advanced\",\n",
    "    description=\"The advanced math agent can break down a complex computation into multiple simple operations and use math_agent to solve them.\",\n",
    "    instruction=agent_math_advanced_instruction,\n",
    "    tools=[AgentTool(agent=simple_math_agent)],\n",
    "    # children=[agent_math],\n",
    "    generate_content_config=types.GenerateContentConfig(temperature=0.2),\n",
    ")\n",
    "\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "\n",
    "def exit_loop(tool_context: ToolContext):\n",
    "  tool_context.actions.escalate = True\n",
    "\n",
    "agent_checker = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"agent_checker\",\n",
    "    description=\"This agent checks if the kid's query is fulfilled. It escalates if both grammar is fixed and the math is calculated\",\n",
    "    instruction=\"\"\"\n",
    "    Analyze the chat log between the user (kids) and other agents.\n",
    "\n",
    "    We are expecting two outcomes from the conversation.\n",
    "    1. agent_grammar helps to fix the grammar of kid's question.\n",
    "    2. agent_math_advanced tries to solve the math step by step.\n",
    "\n",
    "    Decide the action and respond as follows:\n",
    "\n",
    "    1. If both agent_grammar and agent_math_advanced have done their task, summarize the answer in a friendly way to the kid. Then call exit_loop.\n",
    "\n",
    "    2. If there is no pending math problem to solve, friendly tell the kid you help fix grammar and solve math, but does not know anything else. Politely ask for math question. Then call exit_loop.\n",
    "\n",
    "    3. If agent_grammar has fixed the grammar but agent_math_advanced has not generated a final answer with single number, extract corrected_text from most recent JSON response and empahsize that is the math question to solve.\n",
    "\n",
    "    3. Otherwise, say \"Thanks for the question! I'll let grammar and math agent to help you!\". Do not call any tools in this case.\n",
    "\n",
    "    \"\"\",\n",
    "    tools=[exit_loop]\n",
    ")\n",
    "\n",
    "agent_extractor = Agent(\n",
    "    model=MODEL,\n",
    "    name=\"agent_extractor\",\n",
    "    description=\"Extract corrected_text from most recent JSON response and empahsize that is the math question to solve.\",\n",
    "    instruction=\"\"\"\n",
    "    Extract corrected_text from most recent JSON response and empahsize that is the math question to solve.\n",
    "    \"\"\",\n",
    "    generate_content_config=types.GenerateContentConfig(temperature=0.2),\n",
    "    input_schema=OutputSchema,\n",
    ")\n",
    "\n",
    "agent_teaching_assistant_loop = LoopAgent(\n",
    "    name=\"agent_teaching_assistant_loop\",\n",
    "    description=\"This agent acts as a friendly teaching assistant, checking the grammar of kids' questions, performing math calculations using corrected or original text (if grammatically correct), and providing results or grammar feedback in a friendly tone.\",\n",
    "    sub_agents=[agent_checker, agent_grammar, agent_extractor, agent_math_advanced],\n",
    ")\n",
    "\n",
    "root_agent = agent_teaching_assistant_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/trace/__init__.py\", line 587, in use_span\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/opentelemetry/sdk/trace/__init__.py\", line 1105, in start_as_current_span\n",
      "    yield span\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/trace/__init__.py\", line 452, in start_as_current_span\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/adk/agents/base_agent.py\", line 148, in run_async\n",
      "    yield event\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faae476cf40> was created in a different Context\n",
      "ERROR:opentelemetry.context:Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/trace/__init__.py\", line 587, in use_span\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/opentelemetry/sdk/trace/__init__.py\", line 1105, in start_as_current_span\n",
      "    yield span\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/trace/__init__.py\", line 452, in start_as_current_span\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 556, in _call_llm_async\n",
      "    yield llm_response\n",
      "GeneratorExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n",
      "  File \"/home/jupyter/.local/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x7faaf252f100> at 0x7faad4453780> was created in a different Context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Final Response (0.05 ms):\n",
      "Thanks for the question! I'll let grammar and math agent to help you!\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.17 ms):\n",
      "{\n",
      "  \"original_query\": \"Roll a dice of 100 sides and tell me what you got\",\n",
      "  \"corrected_text\": \"Roll a 100-sided die and tell me what you get.\",\n",
      "  \"errors\": [\n",
      "    \"Incorrect article usage ('a dice' should be 'a die').\",\n",
      "    \"Incorrect word choice ('sides' implies multiple, but we're talking about one die with many sides).\",\n",
      "    \"Incorrect tense ('got' should be 'get' for a request).\"\n",
      "  ],\n",
      "  \"explanations\": [\n",
      "    \"When we talk about just one of those number cubes, it's called a 'die' (like saying 'one cookie'). If you have more than one, then they are called 'dice' (like saying 'many cookies').\",\n",
      "    \"It's better to say '100-sided die' because you only have one die, but it has 100 sides!\",\n",
      "    \"When you ask someone to tell you what they will get in the future, it's best to use the word 'get'. 'Got' means you already have it!\"\n",
      "  ]\n",
      "}\n",
      "------------------------------\n",
      ">>> Final Response (0.201 ms):\n",
      "Okay, I have extracted the corrected text from the JSON response.\n",
      "\n",
      "**The math question to solve is: Roll a 100-sided die and tell me what you get.**\n",
      "\n",
      "------------------------------\n",
      ">>> Final Response (0.228 ms):\n",
      "This is not a math question that requires calculation. It's a request to simulate rolling a 100-sided die. I am not capable of generating random numbers.\n",
      "\n",
      "------------------------------\n",
      "+++ Function Calls:\n",
      "Function Name: exit_loop, Args: {}\n",
      "--- Function Responses:\n",
      "Function Name: exit_loop\n",
      "Function Results: [null]\n",
      "Total elapsed time: 0.321 ms\n"
     ]
    }
   ],
   "source": [
    "call = await caller_factory(root_agent=agent_teaching_assistant_loop)\n",
    "pprint_events(call('ok tell me how i can count water.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = create_runner(agent_teaching_assistant_loop)\n",
    "session = await run_session(content_text('Hello!'), runner=runner)\n",
    "session = await run_session(content_text('ok tell me how i can count water.'), runner=runner)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
